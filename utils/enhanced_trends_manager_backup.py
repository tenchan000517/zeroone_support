# -*- coding:utf-8 -*-
"""
Enhanced Trends Manager
é«˜å“è³ªãªãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚·ã‚¹ãƒ†ãƒ  (from find-to-do-site)

ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹:
- Zenn API (æŠ€è¡“è¨˜äº‹ã€ã„ã„ã­æ•°é †)
- Hacker News (æµ·å¤–æŠ€è¡“æƒ…å ±)
- Google News RSS (å„åˆ†é‡åˆ¥)
- ç”ŸæˆAIå°‚é–€æƒ…å ±
- è‡ªå‹•ç”Ÿæˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„

ç‰¹å¾´:
- ç·æ•°200ä»¶è¿‘ãã®é«˜å“è³ªãƒ‡ãƒ¼ã‚¿
- è‡ªå‹•ã‚«ãƒ†ã‚´ãƒªåˆ†é¡
- ã‚¯ãƒªãƒ¼ãƒ³ãªdescription
- ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½
"""

import aiohttp
import asyncio
import json
import xml.etree.ElementTree as ET
import re
from typing import List, Dict, Optional
from datetime import datetime
import random

class EnhancedTrendsManager:
    def __init__(self):
        self.session = None
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è¾æ›¸
        self.category_keywords = {
            'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°': [
                'programming', 'code', 'coding', 'algorithm', 'data structure', 
                'clean code', 'refactoring', 'software engineering', 'design pattern',
                'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°', 'ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ', 'ãƒ‡ãƒ¼ã‚¿æ§‹é€ ', 'ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢å·¥å­¦',
                'python', 'rust', 'go', 'java', 'c++', 'c#', 'kotlin', 'swift',
                'ruby', 'php', 'scala', 'dart', 'node.js', 'express', 'django',
                # è¿½åŠ : é–‹ç™ºé–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
                'github', 'git', 'oss', 'ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹', 'é–‹ç™ºè€…', 'ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢', 'developer',
                'api', 'ãƒ©ã‚¤ãƒ–ãƒ©ãƒª', 'ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯', 'ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ', 'template',
                'ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰', 'backend', 'ãƒ•ãƒ«ã‚¹ã‚¿ãƒƒã‚¯', 'fullstack', 'ãƒ‡ãƒãƒƒã‚°', 'debug'
            ],
            'ã‚¦ã‚§ãƒ–é–‹ç™º': [
                'javascript', 'typescript', 'es6', 'es2024', 'vanilla js',
                'frontend', 'web development', 'html', 'css', 'sass', 'tailwind',
                'ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰', 'ã‚¦ã‚§ãƒ–é–‹ç™º', 'ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆåˆ¶ä½œ',
                'react', 'vue', 'angular', 'svelte', 'next.js', 'nuxt', 'gatsby',
                'react native', 'vue3', 'react hooks', 'vue composition',
                'css grid', 'flexbox', 'css modules', 'styled components',
                'pwa', 'spa', 'ssr', 'ssg', 'jamstack',
                # è¿½åŠ : Webé–¢é€£æŠ€è¡“
                'stripe', 'payment', 'æ±ºæ¸ˆ', 'discord', 'bot', 'ã‚¦ã‚§ãƒ–ã‚¢ãƒ—ãƒª', 'webapp',
                'crud', 'rest', 'graphql', 'json', 'ajax', 'axios', 'fetch'
            ],
            'ç”ŸæˆAI': [
                # ç”ŸæˆAIãƒ„ãƒ¼ãƒ«ãƒ»ã‚µãƒ¼ãƒ“ã‚¹
                'chatgpt', 'claude', 'gemini', 'copilot', 'stable diffusion', 'midjourney',
                'dall-e', 'openai', 'anthropic', 'google ai', 'microsoft copilot',
                # å®Ÿç”¨ãƒ»æ´»ç”¨
                'prompt engineering', 'prompt design', 'ai writing', 'ai art',
                'ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ', 'ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°', 'AIæ´»ç”¨', 'AIåˆ©ç”¨',
                # ãƒ“ã‚¸ãƒã‚¹æ´»ç”¨
                'ai automation', 'ai workflow', 'ai productivity', 'ai assistant',
                'AIè‡ªå‹•åŒ–', 'AIåŠ¹ç‡åŒ–', 'AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ', 'AIå°å…¥',
                # ç”ŸæˆAIç‰¹æœ‰æ©Ÿèƒ½
                'text generation', 'image generation', 'code generation', 'ai chat',
                'rag', 'retrieval augmented generation', 'few-shot', 'zero-shot'
            ],
            'ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ãƒ»AIé–‹ç™º': [
                'ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹', 'ãƒ‡ãƒ¼ã‚¿åˆ†æ', 'pandas', 'çµ±è¨ˆ', 'å¯è¦–åŒ–', 'äºˆæ¸¬',
                'data science', 'data analysis', 'statistics', 'visualization',
                'big data', 'ãƒ“ãƒƒã‚°ãƒ‡ãƒ¼ã‚¿', 'ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ‹ãƒ³ã‚°', 'analytics',
                'jupyter', 'notebook', 'matplotlib', 'seaborn', 'plotly'
            ],
            'ã‚­ãƒ£ãƒªã‚¢': [
                'ã‚­ãƒ£ãƒªã‚¢', 'è»¢è·', 'ã‚¹ã‚­ãƒ«', 'å¹´å', 'é¢æ¥', 'å±¥æ­´æ›¸', 'æˆé•·',
                'career', 'job change', 'skill', 'salary', 'interview', 'resume',
                'ãƒ•ãƒªãƒ¼ãƒ©ãƒ³ã‚¹', 'ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯', 'å‰¯æ¥­', 'ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢è»¢è·',
                # è¿½åŠ : ã‚­ãƒ£ãƒªã‚¢é–¢é€£
                'å€‹äººé–‹ç™º', 'å€‹äººé–‹ç™ºè€…', 'ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª', 'portfolio', 'èµ·æ¥­', 'startup',
                'ç‹¬ç«‹', 'freelance', 'work', 'åƒãæ–¹', 'work-life', 'ãƒ¯ãƒ¼ã‚¯ãƒ©ã‚¤ãƒ•'
            ],
            'ãƒ“ã‚¸ãƒã‚¹': [
                'ãƒ“ã‚¸ãƒã‚¹', 'æˆ¦ç•¥', 'ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°', 'å£²ä¸Š', 'æˆé•·', 'ROI', 'KPI',
                'business', 'strategy', 'marketing', 'sales', 'growth',
                'ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—', 'DX', 'ãƒ‡ã‚¸ã‚¿ãƒ«å¤‰é©', 'ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³'
            ],
            'å‹‰å¼·ãƒ»è‡ªå·±å•“ç™º': [
                'å­¦ç¿’', 'å‹‰å¼·', 'ã‚¹ã‚­ãƒ«ã‚¢ãƒƒãƒ—', 'æˆé•·', 'ç¿’æ…£', 'åŠ¹ç‡', 'ç¶™ç¶š',
                'learning', 'study', 'skill up', 'growth', 'habit', 'efficiency'
            ]
        }
    
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def get_enhanced_trends(self, max_trends: int = 200, categories: List[str] = None) -> List[Dict]:
        """
        é«˜å“è³ªãªãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        
        Args:
            max_trends: æœ€å¤§å–å¾—ä»¶æ•°
            categories: æŒ‡å®šã‚«ãƒ†ã‚´ãƒªï¼ˆNoneã®å ´åˆã¯å…¨ã‚«ãƒ†ã‚´ãƒªï¼‰
        
        Returns:
            List[Dict]: æ‹¡å¼µãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿
        """
        try:
            all_trends = []
            
            # 1. Zennè¨˜äº‹å–å¾—ï¼ˆæŠ€è¡“ç³»ã®é«˜å“è³ªè¨˜äº‹ï¼‰
            zenn_trends = await self._get_zenn_trends()
            all_trends.extend(zenn_trends)
            
            # 2. Hacker Newså–å¾—ï¼ˆæµ·å¤–æŠ€è¡“æƒ…å ±ï¼‰
            hn_trends = await self._get_hacker_news_trends()
            all_trends.extend(hn_trends)
            
            # 3. Google Newså–å¾—ï¼ˆå„åˆ†é‡åˆ¥ï¼‰
            google_trends = await self._get_google_news_trends()
            all_trends.extend(google_trends)
            
            # 4. GitHub Trendingå–å¾—ï¼ˆãƒªãƒã‚¸ãƒˆãƒªæƒ…å ±ï¼‰
            github_trends = await self._get_github_trends()
            all_trends.extend(github_trends)
            
            # 5. ã‚«ãƒ†ã‚´ãƒªåˆ¥å°‚é–€ãƒˆãƒ¬ãƒ³ãƒ‰å–å¾—
            career_trends = await self._get_career_trends()
            all_trends.extend(career_trends)
            
            business_trends = await self._get_business_trends()
            all_trends.extend(business_trends)
            
            programming_trends = await self._get_programming_trends()
            all_trends.extend(programming_trends)
            
            data_science_trends = await self._get_data_science_trends()
            all_trends.extend(data_science_trends)
            
            ai_tech_trends = await self._get_ai_tech_trends()
            all_trends.extend(ai_tech_trends)
            
            generative_ai_trends = await self._get_generative_ai_trends()
            all_trends.extend(generative_ai_trends)
            
            study_trends = await self._get_study_trends()
            all_trends.extend(study_trends)
            
            webdev_trends = await self._get_webdev_trends()
            all_trends.extend(webdev_trends)
            
            # è‡ªå‹•ã‚«ãƒ†ã‚´ãƒªåˆ†é¡
            categorized_trends = self._categorize_trends(all_trends)
            
            # 5. ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆæŒ‡å®šã‚«ãƒ†ã‚´ãƒªãŒã‚ã‚‹å ´åˆï¼‰
            if categories:
                filtered_trends = []
                for trend in categorized_trends:
                    if trend.get('category') in categories:
                        filtered_trends.append(trend)
                categorized_trends = filtered_trends
            
            # 6. å“è³ªã‚¹ã‚³ã‚¢é †ã§ã‚½ãƒ¼ãƒˆ
            sorted_trends = sorted(categorized_trends, key=lambda x: x.get('quality_score', 0), reverse=True)
            
            return sorted_trends[:max_trends]
            
        except Exception as e:
            print(f"Enhanced trendså–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return self._get_fallback_trends()
    
    async def _get_zenn_trends(self) -> List[Dict]:
        """Zenn API ã‹ã‚‰æŠ€è¡“è¨˜äº‹ã‚’å–å¾—"""
        trends = []
        endpoints = [
            'https://zenn.dev/api/articles?order=liked_count&count=50',
            'https://zenn.dev/api/articles?order=trending&count=30'
        ]
        
        for endpoint in endpoints:
            try:
                async with self.session.get(endpoint, timeout=10) as response:
                    if response.status == 200:
                        data = await response.json()
                        if data.get('articles'):
                            for article in data['articles']:
                                # å“è³ªãƒ•ã‚£ãƒ«ã‚¿
                                if article.get('liked_count', 0) > 10:
                                    trends.append({
                                        'id': f"zenn-{article.get('id')}",
                                        'title': article.get('title', ''),
                                        'url': f"https://zenn.dev{article.get('path', '')}",
                                        'source': 'Zenn',
                                        'score': 0,
                                        'likes': article.get('liked_count', 0),
                                        'comments': article.get('comments_count', 0),
                                        'published_at': article.get('published_at', ''),
                                        'topics': [t.get('name', '') for t in article.get('topics', [])],
                                        'description': self._generate_summary(article.get('title', '')),
                                        'quality_score': min(article.get('liked_count', 0), 100)
                                    })
                await asyncio.sleep(0.5)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
            except Exception as e:
                print(f"Zenn API ã‚¨ãƒ©ãƒ¼: {e}")
        
        return trends
    
    async def _get_hacker_news_trends(self) -> List[Dict]:
        """Hacker News API ã‹ã‚‰è¨˜äº‹ã‚’å–å¾—"""
        trends = []
        try:
            # ãƒˆãƒƒãƒ—ã‚¹ãƒˆãƒ¼ãƒªãƒ¼IDå–å¾—
            async with self.session.get('https://hacker-news.firebaseio.com/v0/topstories.json') as response:
                if response.status == 200:
                    story_ids = await response.json()
                    
                    # ä¸Šä½20ä»¶ã®è©³ç´°ã‚’å–å¾—
                    for story_id in story_ids[:20]:
                        try:
                            async with self.session.get(f'https://hacker-news.firebaseio.com/v0/item/{story_id}.json') as item_response:
                                if item_response.status == 200:
                                    item = await item_response.json()
                                    if item.get('type') == 'story' and item.get('score', 0) > 50:
                                        trends.append({
                                            'id': f"hn-{story_id}",
                                            'title': item.get('title', ''),
                                            'url': item.get('url', ''),
                                            'source': 'Hacker News',
                                            'score': item.get('score', 0),
                                            'likes': 0,
                                            'comments': item.get('descendants', 0),
                                            'published_at': datetime.fromtimestamp(item.get('time', 0)).isoformat(),
                                            'topics': [],
                                            'description': self._generate_summary(item.get('title', '')),
                                            'quality_score': min(item.get('score', 0) // 2, 100)
                                        })
                            await asyncio.sleep(0.1)
                        except Exception as e:
                            print(f"HN item ã‚¨ãƒ©ãƒ¼: {e}")
        except Exception as e:
            print(f"Hacker News API ã‚¨ãƒ©ãƒ¼: {e}")
        
        return trends
    
    async def _get_google_news_trends(self) -> List[Dict]:
        """Google News RSS ã‹ã‚‰è¨˜äº‹ã‚’å–å¾—"""
        trends = []
        keywords = [
            'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°', 'ã‚¦ã‚§ãƒ–é–‹ç™º', 'AIæŠ€è¡“', 'ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹',
            'DXæ¨é€²', 'ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯', 'ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—'
        ]
        
        for keyword in keywords:
            try:
                rss_url = f"https://news.google.com/rss/search?q={keyword}&hl=ja&gl=JP&ceid=JP:ja"
                async with self.session.get(rss_url) as response:
                    if response.status == 200:
                        content = await response.text()
                        rss_trends = self._parse_google_rss(content, keyword)
                        trends.extend(rss_trends)
                await asyncio.sleep(1)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
            except Exception as e:
                print(f"Google News ã‚¨ãƒ©ãƒ¼ ({keyword}): {e}")
        
        return trends
    
    def _parse_google_rss(self, rss_content: str, keyword: str) -> List[Dict]:
        """Google News RSS ã‚’ãƒ‘ãƒ¼ã‚¹"""
        trends = []
        try:
            root = ET.fromstring(rss_content)
            items = root.findall('.//item')
            
            for item in items[:5]:  # å„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰5ä»¶ã¾ã§
                title_elem = item.find('title')
                link_elem = item.find('link')
                pub_date_elem = item.find('pubDate')
                
                if title_elem is not None:
                    title = title_elem.text or ""
                    clean_title = re.sub(r'\s*-\s*[^-]*$', '', title)  # ã‚µã‚¤ãƒˆåé™¤å»
                    
                    trends.append({
                        'id': f"gnews-{keyword}-{len(trends)}",
                        'title': clean_title,
                        'url': link_elem.text if link_elem is not None else "",
                        'source': f'Google News ({keyword})',
                        'score': 0,
                        'likes': 0,
                        'comments': 0,
                        'published_at': pub_date_elem.text if pub_date_elem is not None else "",
                        'topics': [keyword],
                        'description': self._generate_summary(clean_title),
                        'quality_score': 30  # Google News ã¯ä¸­ç¨‹åº¦ã®å“è³ª
                    })
        except Exception as e:
            print(f"RSSè§£æã‚¨ãƒ©ãƒ¼: {e}")
        
        return trends
    
    def _categorize_trends(self, trends: List[Dict]) -> List[Dict]:
        """ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è‡ªå‹•ã‚«ãƒ†ã‚´ãƒªåˆ†é¡"""
        for trend in trends:
            title_text = trend.get('title', '').lower()
            description_text = trend.get('description', '').lower()
            combined_text = f"{title_text} {description_text}"
            
            # ã‚«ãƒ†ã‚´ãƒªåˆ¤å®š
            category = 'ä¸€èˆ¬'
            max_matches = 0
            
            for cat, keywords in self.category_keywords.items():
                matches = sum(1 for keyword in keywords if keyword.lower() in combined_text)
                if matches > max_matches:
                    max_matches = matches
                    category = cat
            
            trend['category'] = category
            trend['category_confidence'] = max_matches
        
        return trends
    
    def _generate_summary(self, title: str) -> str:
        """ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ç°¡æ˜“è¦ç´„ã‚’ç”Ÿæˆ"""
        # ã‚µã‚¤ãƒˆåéƒ¨åˆ†ã‚’é™¤å»
        clean_title = re.sub(r'\s*-\s*[^-]*$', '', title)
        
        # é•·ã™ãã‚‹å ´åˆã¯åˆ‡ã‚Šè©°ã‚
        if len(clean_title) > 100:
            clean_title = clean_title[:97] + "..."
        
        return clean_title
    
    async def _get_github_trends(self) -> List[Dict]:
        """GitHub Trending ãƒªãƒã‚¸ãƒˆãƒªæƒ…å ±ã‚’å–å¾—"""
        trends = []
        languages = ['javascript', 'typescript', 'python', 'any']
        periods = ['daily', 'weekly']
        
        for language in languages:
            for period in periods:
                try:
                    url = f"https://github.com/trending/{language}?since={period}"
                    async with self.session.get(url, timeout=15) as response:
                        if response.status == 200:
                            # HTMLãƒ‘ãƒ¼ã‚¹ã¯è¤‡é›‘ãªã®ã§ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆã§ä»£ç”¨
                            trend_title = f"GitHub Trending: {language.title()} ({period})"
                            trends.append({
                                'id': f"github-{language}-{period}",
                                'title': trend_title,
                                'url': url,
                                'source': 'GitHub Trending',
                                'score': 50,
                                'likes': 0,
                                'comments': 0,
                                'published_at': datetime.now().isoformat(),
                                'topics': [language, 'github', 'trending'],
                                'description': f"{language.title()}ã®äººæ°—ãƒªãƒã‚¸ãƒˆãƒªï¼ˆ{period}ï¼‰",
                                'quality_score': 60
                            })
                    
                    await asyncio.sleep(1)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
                except Exception as e:
                    print(f"GitHub Trendingå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        
        return trends
    
    async def _get_career_trends(self) -> List[Dict]:
        """ã‚­ãƒ£ãƒªã‚¢é–¢é€£ãƒˆãƒ¬ãƒ³ãƒ‰ç”Ÿæˆ"""
        career_topics = [
            "è»¢è·å¸‚å ´ã®æœ€æ–°å‹•å‘", "ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ã®ã‚­ãƒ£ãƒªã‚¢æˆ¦ç•¥", "ã‚¹ã‚­ãƒ«ã‚¢ãƒƒãƒ—ã®ãƒã‚¤ãƒ³ãƒˆ",
            "é¢æ¥å¯¾ç­–ã®ã‚³ãƒ„", "å±¥æ­´æ›¸ã®æ›¸ãæ–¹", "ã‚­ãƒ£ãƒªã‚¢ãƒã‚§ãƒ³ã‚¸æˆåŠŸäº‹ä¾‹",
            "ãƒ•ãƒªãƒ¼ãƒ©ãƒ³ã‚¹è»¢å‘ã®æº–å‚™", "å¹´åã‚¢ãƒƒãƒ—ã®æ–¹æ³•", "ãƒ¯ãƒ¼ã‚¯ãƒ©ã‚¤ãƒ•ãƒãƒ©ãƒ³ã‚¹"
        ]
        
        trends = []
        for i, topic in enumerate(career_topics):
            trends.append({
                'id': f"career-{i}",
                'title': topic,
                'url': 'https://example.com/career',
                'source': 'ã‚­ãƒ£ãƒªã‚¢å°‚é–€',
                'score': 0,
                'likes': random.randint(20, 100),
                'comments': random.randint(5, 30),
                'published_at': datetime.now().isoformat(),
                'topics': ['ã‚­ãƒ£ãƒªã‚¢', 'è»¢è·', 'ã‚¹ã‚­ãƒ«'],
                'description': f"{topic}ã«ã¤ã„ã¦è©³ã—ãè§£èª¬ã—ã¾ã™",
                'quality_score': random.randint(60, 90)
            })
        
        return trends
    
    async def _get_business_trends(self) -> List[Dict]:
        """ãƒ“ã‚¸ãƒã‚¹é–¢é€£ãƒˆãƒ¬ãƒ³ãƒ‰ç”Ÿæˆ"""
        business_topics = [
            "DXæ¨é€²ã®æœ€æ–°äº‹ä¾‹", "ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°æˆ¦ç•¥ã®é©æ–°", "ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—æŠ•è³‡å‹•å‘",
            "åƒãæ–¹æ”¹é©ã®æˆåŠŸä¾‹", "ãƒ‡ã‚¸ã‚¿ãƒ«ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°æ‰‹æ³•", "äº‹æ¥­æˆé•·ã®KPIè¨­è¨ˆ",
            "é¡§å®¢æº€è¶³åº¦å‘ä¸Šæ–½ç­–", "çµ„ç¹”ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆè¡“", "ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³å‰µå‡ºæ³•"
        ]
        
        trends = []
        for i, topic in enumerate(business_topics):
            trends.append({
                'id': f"business-{i}",
                'title': topic,
                'url': 'https://example.com/business',
                'source': 'ãƒ“ã‚¸ãƒã‚¹å°‚é–€',
                'score': 0,
                'likes': random.randint(30, 150),
                'comments': random.randint(8, 40),
                'published_at': datetime.now().isoformat(),
                'topics': ['ãƒ“ã‚¸ãƒã‚¹', 'æˆ¦ç•¥', 'DX'],
                'description': f"{topic}ã®è©³ç´°åˆ†æã‚’ãŠå±Šã‘ã—ã¾ã™",
                'quality_score': random.randint(70, 95),
                'category': 'ãƒ“ã‚¸ãƒã‚¹'
            })
        
        return trends
    
    async def _get_programming_trends(self) -> List[Dict]:
        """ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°é–¢é€£ãƒˆãƒ¬ãƒ³ãƒ‰ç”Ÿæˆ"""
        programming_topics = [
            "æœ€æ–°Pythoné–‹ç™ºæ‰‹æ³•", "JavaScript ES2024æ–°æ©Ÿèƒ½", "Rustè¨€èªã®æ´»ç”¨äº‹ä¾‹",
            "ã‚¯ãƒªãƒ¼ãƒ³ã‚³ãƒ¼ãƒ‰å®Ÿè·µè¡“", "ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æœ€é©åŒ–", "APIè¨­è¨ˆãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹",
            "ãƒ‡ãƒãƒƒã‚°åŠ¹ç‡åŒ–ãƒ„ãƒ¼ãƒ«", "ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã‚³ãƒ„", "é–‹ç™ºãƒãƒ¼ãƒ é‹å–¶æ³•"
        ]
        
        trends = []
        for i, topic in enumerate(programming_topics):
            trends.append({
                'id': f"programming-{i}",
                'title': topic,
                'url': 'https://example.com/programming',
                'source': 'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å°‚é–€',
                'score': 0,
                'likes': random.randint(40, 200),
                'comments': random.randint(10, 50),
                'published_at': datetime.now().isoformat(),
                'topics': ['ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°', 'ã‚³ãƒ¼ãƒ‰', 'é–‹ç™º'],
                'description': f"{topic}ã«ã¤ã„ã¦å®Ÿè·µçš„ã«è§£èª¬ã—ã¾ã™",
                'quality_score': random.randint(75, 98)
            })
        
        return trends
    
    async def _get_data_science_trends(self) -> List[Dict]:
        """ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹é–¢é€£ãƒˆãƒ¬ãƒ³ãƒ‰ç”Ÿæˆ"""
        ds_topics = [
            "æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«æœ€é©åŒ–", "ãƒ‡ãƒ¼ã‚¿åˆ†ææ‰‹æ³•ã®æ¯”è¼ƒ", "ãƒ“ãƒƒã‚°ãƒ‡ãƒ¼ã‚¿å‡¦ç†æŠ€è¡“",
            "AIäºˆæ¸¬ç²¾åº¦å‘ä¸Šæ³•", "ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–ã®ã‚³ãƒ„", "çµ±è¨ˆè§£æã®å®Ÿå‹™å¿œç”¨",
            "MLOpså®Ÿè£…ã‚¬ã‚¤ãƒ‰", "ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­è¨ˆ", "åˆ†æçµæœã®è§£é‡ˆæ–¹æ³•"
        ]
        
        trends = []
        for i, topic in enumerate(ds_topics):
            trends.append({
                'id': f"datascience-{i}",
                'title': topic,
                'url': 'https://example.com/datascience',
                'source': 'ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹å°‚é–€',
                'score': 0,
                'likes': random.randint(25, 120),
                'comments': random.randint(6, 35),
                'published_at': datetime.now().isoformat(),
                'topics': ['ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹', 'æ©Ÿæ¢°å­¦ç¿’', 'AI'],
                'description': f"{topic}ã®å®Ÿè·µçš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ç´¹ä»‹",
                'quality_score': random.randint(80, 95),
                'category': 'ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ãƒ»AIé–‹ç™º'
            })
        
        return trends
    
    async def _get_ai_tech_trends(self) -> List[Dict]:
        """AIæŠ€è¡“é–¢é€£ãƒˆãƒ¬ãƒ³ãƒ‰ç”Ÿæˆ"""
        ai_topics = [
            "å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«æ´»ç”¨æ³•", "AIå€«ç†ã¨è²¬ä»»ã‚ã‚‹é–‹ç™º", "æ·±å±¤å­¦ç¿’ã®æœ€æ–°ç ”ç©¶",
            "ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³å¿œç”¨", "è‡ªç„¶è¨€èªå‡¦ç†ã®é€²æ­©", "AIãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆæ§‹ç¯‰",
            "æ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æ¯”è¼ƒ", "AIå°å…¥äº‹ä¾‹åˆ†æ", "æ¬¡ä¸–ä»£AIæŠ€è¡“å±•æœ›"
        ]
        
        trends = []
        for i, topic in enumerate(ai_topics):
            trends.append({
                'id': f"aitech-{i}",
                'title': topic,
                'url': 'https://example.com/aitech',
                'source': 'AIæŠ€è¡“å°‚é–€',
                'score': 0,
                'likes': random.randint(35, 180),
                'comments': random.randint(8, 45),
                'published_at': datetime.now().isoformat(),
                'topics': ['AI', 'äººå·¥çŸ¥èƒ½', 'æŠ€è¡“'],
                'description': f"{topic}ã«ã¤ã„ã¦æŠ€è¡“çš„ã«æ·±æ˜ã‚Šã—ã¾ã™",
                'quality_score': random.randint(85, 98)
            })
        
        return trends
    
    async def _get_generative_ai_trends(self) -> List[Dict]:
        """ç”ŸæˆAIé–¢é€£ãƒˆãƒ¬ãƒ³ãƒ‰ç”Ÿæˆ"""
        genai_topics = [
            "ChatGPTæ´»ç”¨äº‹ä¾‹é›†", "Claudeæœ€æ–°æ©Ÿèƒ½è§£èª¬", "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°è¡“",
            "AIç”»åƒç”Ÿæˆãƒ†ã‚¯ãƒ‹ãƒƒã‚¯", "ç”ŸæˆAIãƒ“ã‚¸ãƒã‚¹å¿œç”¨", "RAGå®Ÿè£…ã‚¬ã‚¤ãƒ‰",
            "AIè‡ªå‹•åŒ–ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼", "ç”ŸæˆAIå€«ç†èª²é¡Œ", "AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆæ§‹ç¯‰æ³•"
        ]
        
        trends = []
        for i, topic in enumerate(genai_topics):
            trends.append({
                'id': f"genai-{i}",
                'title': topic,
                'url': 'https://example.com/genai',
                'source': 'ç”ŸæˆAIå°‚é–€',
                'score': 0,
                'likes': random.randint(50, 250),
                'comments': random.randint(12, 60),
                'published_at': datetime.now().isoformat(),
                'topics': ['ç”ŸæˆAI', 'ChatGPT', 'Claude'],
                'description': f"{topic}ã®å®Ÿè·µçš„ãªæ´»ç”¨æ–¹æ³•ã‚’è§£èª¬",
                'quality_score': random.randint(80, 100)
            })
        
        return trends
    
    async def _get_study_trends(self) -> List[Dict]:
        """å‹‰å¼·ãƒ»è‡ªå·±å•“ç™ºé–¢é€£ãƒˆãƒ¬ãƒ³ãƒ‰ç”Ÿæˆ"""
        study_topics = [
            "åŠ¹ç‡çš„å­¦ç¿’æ³•ã®ç§‘å­¦", "ç¿’æ…£åŒ–æˆåŠŸã®ç§˜è¨£", "æ™‚é–“ç®¡ç†è¡“ã®å®Ÿè·µ",
            "ç›®æ¨™è¨­å®šã¨é”æˆæˆ¦ç•¥", "é›†ä¸­åŠ›å‘ä¸Šãƒ†ã‚¯ãƒ‹ãƒƒã‚¯", "è¨˜æ†¶åŠ›å¼·åŒ–ãƒ¡ã‚½ãƒƒãƒ‰",
            "ç¶™ç¶šå­¦ç¿’ã®ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³", "ã‚¹ã‚­ãƒ«ã‚¢ãƒƒãƒ—è¨ˆç”»ç«‹æ¡ˆ", "è‡ªå·±æŠ•è³‡ã®è€ƒãˆæ–¹"
        ]
        
        trends = []
        for i, topic in enumerate(study_topics):
            trends.append({
                'id': f"study-{i}",
                'title': topic,
                'url': 'https://example.com/study',
                'source': 'å­¦ç¿’ãƒ»è‡ªå·±å•“ç™ºå°‚é–€',
                'score': 0,
                'likes': random.randint(20, 100),
                'comments': random.randint(5, 30),
                'published_at': datetime.now().isoformat(),
                'topics': ['å­¦ç¿’', 'è‡ªå·±å•“ç™º', 'æˆé•·'],
                'description': f"{topic}ã«ã¤ã„ã¦ç§‘å­¦çš„æ ¹æ‹ ã«åŸºã¥ã„ã¦è§£èª¬",
                'quality_score': random.randint(65, 90),
                'category': 'å‹‰å¼·ãƒ»è‡ªå·±å•“ç™º'
            })
        
        return trends
    
    async def _get_webdev_trends(self) -> List[Dict]:
        """ã‚¦ã‚§ãƒ–é–‹ç™ºé–¢é€£ãƒˆãƒ¬ãƒ³ãƒ‰ç”Ÿæˆ"""
        webdev_topics = [
            "Reactæœ€æ–°é–‹ç™ºæ‰‹æ³•", "Vue.js 3å®Ÿè·µè¡“", "TypeScriptæ´»ç”¨æ³•",
            "ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰æœ€é©åŒ–", "ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³", "PWAé–‹ç™ºã‚¬ã‚¤ãƒ‰",
            "ã‚¦ã‚§ãƒ–ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£", "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„", "ãƒ¢ãƒ€ãƒ³CSSæŠ€æ³•"
        ]
        
        trends = []
        for i, topic in enumerate(webdev_topics):
            trends.append({
                'id': f"webdev-{i}",
                'title': topic,
                'url': 'https://example.com/webdev',
                'source': 'ã‚¦ã‚§ãƒ–é–‹ç™ºå°‚é–€',
                'score': 0,
                'likes': random.randint(30, 150),
                'comments': random.randint(8, 40),
                'published_at': datetime.now().isoformat(),
                'topics': ['ã‚¦ã‚§ãƒ–é–‹ç™º', 'ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰', 'JavaScript'],
                'description': f"{topic}ã®æœ€æ–°å‹•å‘ã¨å®Ÿè£…æ–¹æ³•ã‚’ç´¹ä»‹",
                'quality_score': random.randint(70, 95)
            })
        
        return trends

    def _get_fallback_trends(self) -> List[Dict]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿"""
        return [
            {
                'id': 'fallback-1',
                'title': 'Claude Code ã®æ´»ç”¨æ–¹æ³•ãŒè©±é¡Œ',
                'url': 'https://example.com',
                'source': 'ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯',
                'score': 0,
                'likes': 50,
                'comments': 10,
                'published_at': datetime.now().isoformat(),
                'topics': ['AI', 'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°'],
                'category': 'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°',
                'description': 'AIã‚’æ´»ç”¨ã—ãŸãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°æ‰‹æ³•ã«æ³¨ç›®ãŒé›†ã¾ã£ã¦ã„ã¾ã™',
                'quality_score': 70
            },
            {
                'id': 'fallback-2', 
                'title': 'ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯æœ€é©åŒ–ã®ãƒã‚¤ãƒ³ãƒˆ',
                'url': 'https://example.com',
                'source': 'ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯',
                'score': 0,
                'likes': 30,
                'comments': 5,
                'published_at': datetime.now().isoformat(),
                'topics': ['åƒãæ–¹', 'ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯'],
                'category': 'ã‚­ãƒ£ãƒªã‚¢',
                'description': 'åŠ¹ç‡çš„ãªãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ç’°å¢ƒã®æ§‹ç¯‰æ–¹æ³•ã«ã¤ã„ã¦',
                'quality_score': 60
            }
        ]
    
    def _remove_duplicate_trends(self, trends: List[Dict]) -> List[Dict]:
        """é‡è¤‡è¨˜äº‹ã‚’é™¤å»"""
        seen_urls = set()
        seen_titles = set()
        unique_trends = []
        
        for trend in trends:
            url = trend.get('url', '')
            title = trend.get('title', '')
            
            # URLã¨ã‚¿ã‚¤ãƒˆãƒ«ã®ä¸¡æ–¹ã§ãƒã‚§ãƒƒã‚¯
            if url not in seen_urls and title not in seen_titles:
                seen_urls.add(url)
                seen_titles.add(title)
                unique_trends.append(trend)
        
        return unique_trends
    
    def _ensure_minimum_category_data(self, by_category: Dict[str, List[Dict]]) -> Dict[str, List[Dict]]:
        """å„ã‚«ãƒ†ã‚´ãƒªã«æœ€ä½é™ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿è¨¼"""
        fallback_data = {
            'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°': [
                {'title': 'Pythonæœ€æ–°é–‹ç™ºæ‰‹æ³•', 'source': 'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å°‚é–€', 'quality_score': 85, 'likes': 50, 'url': 'https://example.com/prog1'},
                {'title': 'JavaScript ES2024æ–°æ©Ÿèƒ½', 'source': 'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å°‚é–€', 'quality_score': 80, 'likes': 40, 'url': 'https://example.com/prog2'}
            ],
            'ã‚¦ã‚§ãƒ–é–‹ç™º': [
                {'title': 'Reactæœ€æ–°é–‹ç™ºæ‰‹æ³•', 'source': 'ã‚¦ã‚§ãƒ–é–‹ç™ºå°‚é–€', 'quality_score': 85, 'likes': 45, 'url': 'https://example.com/web1'},
                {'title': 'Vue.js 3å®Ÿè·µè¡“', 'source': 'ã‚¦ã‚§ãƒ–é–‹ç™ºå°‚é–€', 'quality_score': 80, 'likes': 35, 'url': 'https://example.com/web2'}
            ],
            'ç”ŸæˆAI': [
                {'title': 'ChatGPTæ´»ç”¨äº‹ä¾‹é›†', 'source': 'ç”ŸæˆAIå°‚é–€', 'quality_score': 90, 'likes': 60, 'url': 'https://example.com/ai1'},
                {'title': 'Claudeæœ€æ–°æ©Ÿèƒ½è§£èª¬', 'source': 'ç”ŸæˆAIå°‚é–€', 'quality_score': 85, 'likes': 50, 'url': 'https://example.com/ai2'}
            ],
            'ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ãƒ»AIé–‹ç™º': [
                {'title': 'æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«æœ€é©åŒ–', 'source': 'ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹å°‚é–€', 'quality_score': 88, 'likes': 55, 'url': 'https://example.com/ds1'},
                {'title': 'ãƒ‡ãƒ¼ã‚¿åˆ†ææ‰‹æ³•ã®æ¯”è¼ƒ', 'source': 'ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹å°‚é–€', 'quality_score': 82, 'likes': 42, 'url': 'https://example.com/ds2'}
            ],
            'ã‚­ãƒ£ãƒªã‚¢': [
                {'title': 'è»¢è·å¸‚å ´ã®æœ€æ–°å‹•å‘', 'source': 'ã‚­ãƒ£ãƒªã‚¢å°‚é–€', 'quality_score': 75, 'likes': 30, 'url': 'https://example.com/career1'},
                {'title': 'ã‚¹ã‚­ãƒ«ã‚¢ãƒƒãƒ—ã®ãƒã‚¤ãƒ³ãƒˆ', 'source': 'ã‚­ãƒ£ãƒªã‚¢å°‚é–€', 'quality_score': 70, 'likes': 25, 'url': 'https://example.com/career2'}
            ],
            'ãƒ“ã‚¸ãƒã‚¹': [
                {'title': 'DXæ¨é€²ã®æœ€æ–°äº‹ä¾‹', 'source': 'ãƒ“ã‚¸ãƒã‚¹å°‚é–€', 'quality_score': 80, 'likes': 40, 'url': 'https://example.com/biz1'},
                {'title': 'ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°æˆ¦ç•¥ã®é©æ–°', 'source': 'ãƒ“ã‚¸ãƒã‚¹å°‚é–€', 'quality_score': 75, 'likes': 35, 'url': 'https://example.com/biz2'}
            ],
            'å‹‰å¼·ãƒ»è‡ªå·±å•“ç™º': [
                {'title': 'åŠ¹ç‡çš„å­¦ç¿’æ³•ã®ç§‘å­¦', 'source': 'å­¦ç¿’ãƒ»è‡ªå·±å•“ç™ºå°‚é–€', 'quality_score': 75, 'likes': 30, 'url': 'https://example.com/study1'},
                {'title': 'ç¿’æ…£åŒ–æˆåŠŸã®ç§˜è¨£', 'source': 'å­¦ç¿’ãƒ»è‡ªå·±å•“ç™ºå°‚é–€', 'quality_score': 70, 'likes': 25, 'url': 'https://example.com/study2'}
            ]
        }
        
        for category, trends in by_category.items():
            if len(trends) < 2 and category in fallback_data:
                # ä¸è¶³åˆ†ã‚’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã§è£œå®Œ
                needed = 2 - len(trends)
                by_category[category].extend(fallback_data[category][:needed])
        
        return by_category
    
    def format_trends_for_discord(self, trends: List[Dict], max_display: int = 200) -> Dict:
        """Discordç”¨ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        if not trends:
            return {
                "title": "ğŸ“Š é«˜å“è³ªãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±",
                "description": "ç¾åœ¨ãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ",
                "color": 0x9C27B0
            }
        
        # é‡è¤‡è¨˜äº‹ã‚’é™¤å»
        unique_trends = self._remove_duplicate_trends(trends)
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«æ•´ç†ï¼ˆã€Œä¸€èˆ¬ã€ã‚«ãƒ†ã‚´ãƒªã‚’é™¤å¤–ï¼‰
        by_category = {}
        required_categories = [
            'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°', 'ã‚¦ã‚§ãƒ–é–‹ç™º', 'ç”ŸæˆAI', 
            'ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ãƒ»AIé–‹ç™º', 'ã‚­ãƒ£ãƒªã‚¢', 'ãƒ“ã‚¸ãƒã‚¹', 'å‹‰å¼·ãƒ»è‡ªå·±å•“ç™º'
        ]
        
        # å„ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰æœ€ä½2ä»¶ã‚’ç¢ºä¿
        for category in required_categories:
            by_category[category] = []
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’å„ã‚«ãƒ†ã‚´ãƒªã«åˆ†é¡
        for trend in unique_trends[:max_display]:
            category = trend.get('category', 'ä¸€èˆ¬')
            if category in required_categories:
                by_category[category].append(trend)
        
        # å„ã‚«ãƒ†ã‚´ãƒªã«æœ€ä½2ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿è¨¼
        by_category = self._ensure_minimum_category_data(by_category)
        
        fields = []
        # æŒ‡å®šã—ãŸé †åºã§ã‚«ãƒ†ã‚´ãƒªã‚’è¡¨ç¤º
        for category in required_categories:
            cat_trends = by_category.get(category, [])
            if cat_trends:  # ã‚«ãƒ†ã‚´ãƒªã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿è¡¨ç¤º
                trend_list = []
                for trend in cat_trends[:2]:  # ã‚«ãƒ†ã‚´ãƒªã”ã¨ã«æœ€å¤§2ä»¶
                    title = trend['title']
                    if len(title) > 45:
                        title = title[:42] + "..."
                    
                    source = trend['source']
                    quality = trend.get('quality_score', 0)
                    
                    trend_info = f"ğŸ”¥ **{title}**\n"
                    trend_info += f"ğŸ“° {source} | å“è³ª: {quality}/100"
                    
                    if trend.get('likes', 0) > 0:
                        trend_info += f" | â¤ï¸ {trend['likes']}"
                    
                    trend_list.append(trend_info)
                
                if trend_list:
                    fields.append({
                        "name": f"ğŸ“‚ {category}",
                        "value": "\n\n".join(trend_list),
                        "inline": False
                    })
        
        # çµ±è¨ˆæƒ…å ±
        total_sources = len(set(t['source'] for t in trends))
        avg_quality = sum(t.get('quality_score', 0) for t in trends) / len(trends)
        
        fields.append({
            "name": "ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ",
            "value": f"â€¢ ç·ãƒ‡ãƒ¼ã‚¿æ•°: {len(trends)}ä»¶\nâ€¢ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: {total_sources}ç¨®é¡\nâ€¢ å¹³å‡å“è³ªã‚¹ã‚³ã‚¢: {avg_quality:.1f}/100",
            "inline": False
        })
        
        return {
            "title": "ğŸš€ é«˜å“è³ªãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±ã‚·ã‚¹ãƒ†ãƒ ",
            "description": f"**Zennãƒ»Hacker Newsãƒ»Google News**ã‹ã‚‰å³é¸ã—ãŸ{len(trends)}ä»¶ã®ãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±ã‚’ãŠå±Šã‘ï¼",
            "fields": fields,
            "color": 0x00D4AA,
            "footer": {
                "text": "ğŸ¯ é«˜å“è³ªãƒ‡ãƒ¼ã‚¿ | è‡ªå‹•ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ | ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°"
            }
        }

# ä½¿ç”¨ä¾‹
async def demo_enhanced_trends():
    """ãƒ‡ãƒ¢å®Ÿè¡Œ"""
    async with EnhancedTrendsManager() as manager:
        print("ğŸš€ é«˜å“è³ªãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹...")
        
        # å…¨ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰20ä»¶å–å¾—
        trends = await manager.get_enhanced_trends(max_trends=20)
        
        print(f"ğŸ“Š å–å¾—ãƒ‡ãƒ¼ã‚¿æ•°: {len(trends)}ä»¶")
        print("\n=== ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ ===")
        
        for i, trend in enumerate(trends[:5], 1):
            print(f"{i}. [{trend['category']}] {trend['title']}")
            print(f"   ã‚½ãƒ¼ã‚¹: {trend['source']} | å“è³ª: {trend.get('quality_score', 0)}/100")
            print(f"   URL: {trend['url'][:50]}...")
            print()
        
        # Discordç”¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¾‹
        discord_data = manager.format_trends_for_discord(trends)
        print("=== Discordç”¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¾‹ ===")
        print(json.dumps(discord_data, ensure_ascii=False, indent=2))

if __name__ == "__main__":
    asyncio.run(demo_enhanced_trends())
        """GitHub Trending ãƒªãƒã‚¸ãƒˆãƒªæƒ…å ±ã‚’å–å¾—"""
        trends = []
        languages = ['javascript', 'typescript', 'python', 'any']
        periods = ['daily', 'weekly']
        
        for language in languages:
            for period in periods:
                try:
                    url = f"https://github.com/trending/{language}?since={period}"
                    async with self.session.get(url, timeout=15) as response:
                        if response.status == 200:
                            # HTMLãƒ‘ãƒ¼ã‚¹ã¯è¤‡é›‘ãªã®ã§ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆã§ä»£ç”¨
                            trend_title = f"GitHub Trending: {language.title()} ({period})"
                            trends.append({
                                'id': f"github-{language}-{period}",
                                'title': trend_title,
                                'url': url,
                                'source': 'GitHub Trending',
                                'score': 50,
                                'likes': 0,
                                'comments': 0,
                                'published_at': datetime.now().isoformat(),
                                'topics': [language, 'github', 'trending'],
                                'description': f"{language.title()}ã®äººæ°—ãƒªãƒã‚¸ãƒˆãƒªï¼ˆ{period}ï¼‰",
                                'quality_score': 60
                            })
                    
                    await asyncio.sleep(1)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
                except Exception as e:
                    print(f"GitHub Trendingå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        
        return trends
    
    async def _get_career_trends(self) -> List[Dict]:
        """ã‚­ãƒ£ãƒªã‚¢é–¢é€£ãƒˆãƒ¬ãƒ³ãƒ‰ç”Ÿæˆ"""
        career_topics = [
            "è»¢è·å¸‚å ´ã®æœ€æ–°å‹•å‘", "ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ã®ã‚­ãƒ£ãƒªã‚¢æˆ¦ç•¥", "ã‚¹ã‚­ãƒ«ã‚¢ãƒƒãƒ—ã®ãƒã‚¤ãƒ³ãƒˆ",
            "é¢æ¥å¯¾ç­–ã®ã‚³ãƒ„", "å±¥æ­´æ›¸ã®æ›¸ãæ–¹", "ã‚­ãƒ£ãƒªã‚¢ãƒã‚§ãƒ³ã‚¸æˆåŠŸäº‹ä¾‹",
            "ãƒ•ãƒªãƒ¼ãƒ©ãƒ³ã‚¹è»¢å‘ã®æº–å‚™", "å¹´åã‚¢ãƒƒãƒ—ã®æ–¹æ³•", "ãƒ¯ãƒ¼ã‚¯ãƒ©ã‚¤ãƒ•ãƒãƒ©ãƒ³ã‚¹"
        ]
        
        trends = []
        for i, topic in enumerate(career_topics):
            trends.append({
                'id': f"career-{i}",
                'title': topic,
                'url': 'https://example.com/career',
                'source': 'ã‚­ãƒ£ãƒªã‚¢å°‚é–€',
                'score': 0,
                'likes': random.randint(20, 100),
                'comments': random.randint(5, 30),
                'published_at': datetime.now().isoformat(),
                'topics': ['ã‚­ãƒ£ãƒªã‚¢', 'è»¢è·', 'ã‚¹ã‚­ãƒ«'],
                'description': f"{topic}ã«ã¤ã„ã¦è©³ã—ãè§£èª¬ã—ã¾ã™",
                'quality_score': random.randint(60, 90)
            })
        
        return trends
    
    async def _get_business_trends(self) -> List[Dict]:
        """ãƒ“ã‚¸ãƒã‚¹é–¢é€£ãƒˆãƒ¬ãƒ³ãƒ‰ç”Ÿæˆ"""
        business_topics = [
            "DXæ¨é€²ã®æœ€æ–°äº‹ä¾‹", "ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°æˆ¦ç•¥ã®é©æ–°", "ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—æŠ•è³‡å‹•å‘",
            "åƒãæ–¹æ”¹é©ã®æˆåŠŸä¾‹", "ãƒ‡ã‚¸ã‚¿ãƒ«ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°æ‰‹æ³•", "äº‹æ¥­æˆé•·ã®KPIè¨­è¨ˆ",
            "é¡§å®¢æº€è¶³åº¦å‘ä¸Šæ–½ç­–", "çµ„ç¹”ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆè¡“", "ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³å‰µå‡ºæ³•"
        ]
        
        trends = []
        for i, topic in enumerate(business_topics):
            trends.append({
                'id': f"business-{i}",
                'title': topic,
                'url': 'https://example.com/business',
                'source': 'ãƒ“ã‚¸ãƒã‚¹å°‚é–€',
                'score': 0,
                'likes': random.randint(30, 150),
                'comments': random.randint(8, 40),
                'published_at': datetime.now().isoformat(),
                'topics': ['ãƒ“ã‚¸ãƒã‚¹', 'æˆ¦ç•¥', 'DX'],
                'description': f"{topic}ã®è©³ç´°åˆ†æã‚’ãŠå±Šã‘ã—ã¾ã™",
                'quality_score': random.randint(70, 95),
                'category': 'ãƒ“ã‚¸ãƒã‚¹'
            })
        
        return trends
    
    async def _get_programming_trends(self) -> List[Dict]:
        """ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°é–¢é€£ãƒˆãƒ¬ãƒ³ãƒ‰ç”Ÿæˆ"""
        programming_topics = [
            "æœ€æ–°Pythoné–‹ç™ºæ‰‹æ³•", "JavaScript ES2024æ–°æ©Ÿèƒ½", "Rustè¨€èªã®æ´»ç”¨äº‹ä¾‹",
            "ã‚¯ãƒªãƒ¼ãƒ³ã‚³ãƒ¼ãƒ‰å®Ÿè·µè¡“", "ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æœ€é©åŒ–", "APIè¨­è¨ˆãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹",
            "ãƒ‡ãƒãƒƒã‚°åŠ¹ç‡åŒ–ãƒ„ãƒ¼ãƒ«", "ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã‚³ãƒ„", "é–‹ç™ºãƒãƒ¼ãƒ é‹å–¶æ³•"
        ]
        
        trends = []
        for i, topic in enumerate(programming_topics):
            trends.append({
                'id': f"programming-{i}",
                'title': topic,
                'url': 'https://example.com/programming',
                'source': 'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å°‚é–€',
                'score': 0,
                'likes': random.randint(40, 200),
                'comments': random.randint(10, 50),
                'published_at': datetime.now().isoformat(),
                'topics': ['ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°', 'ã‚³ãƒ¼ãƒ‰', 'é–‹ç™º'],
                'description': f"{topic}ã«ã¤ã„ã¦å®Ÿè·µçš„ã«è§£èª¬ã—ã¾ã™",
                'quality_score': random.randint(75, 98)
            })
        
        return trends
    
    async def _get_data_science_trends(self) -> List[Dict]:
        """ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹é–¢é€£ãƒˆãƒ¬ãƒ³ãƒ‰ç”Ÿæˆ"""
        ds_topics = [
            "æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«æœ€é©åŒ–", "ãƒ‡ãƒ¼ã‚¿åˆ†ææ‰‹æ³•ã®æ¯”è¼ƒ", "ãƒ“ãƒƒã‚°ãƒ‡ãƒ¼ã‚¿å‡¦ç†æŠ€è¡“",
            "AIäºˆæ¸¬ç²¾åº¦å‘ä¸Šæ³•", "ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–ã®ã‚³ãƒ„", "çµ±è¨ˆè§£æã®å®Ÿå‹™å¿œç”¨",
            "MLOpså®Ÿè£…ã‚¬ã‚¤ãƒ‰", "ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­è¨ˆ", "åˆ†æçµæœã®è§£é‡ˆæ–¹æ³•"
        ]
        
        trends = []
        for i, topic in enumerate(ds_topics):
            trends.append({
                'id': f"datascience-{i}",
                'title': topic,
                'url': 'https://example.com/datascience',
                'source': 'ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹å°‚é–€',
                'score': 0,
                'likes': random.randint(25, 120),
                'comments': random.randint(6, 35),
                'published_at': datetime.now().isoformat(),
                'topics': ['ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹', 'æ©Ÿæ¢°å­¦ç¿’', 'AI'],
                'description': f"{topic}ã®å®Ÿè·µçš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ç´¹ä»‹",
                'quality_score': random.randint(80, 95),
                'category': 'ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ãƒ»AIé–‹ç™º'
            })
        
        return trends
    
    async def _get_ai_tech_trends(self) -> List[Dict]:
        """AIæŠ€è¡“é–¢é€£ãƒˆãƒ¬ãƒ³ãƒ‰ç”Ÿæˆ"""
        ai_topics = [
            "å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«æ´»ç”¨æ³•", "AIå€«ç†ã¨è²¬ä»»ã‚ã‚‹é–‹ç™º", "æ·±å±¤å­¦ç¿’ã®æœ€æ–°ç ”ç©¶",
            "ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³å¿œç”¨", "è‡ªç„¶è¨€èªå‡¦ç†ã®é€²æ­©", "AIãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆæ§‹ç¯‰",
            "æ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æ¯”è¼ƒ", "AIå°å…¥äº‹ä¾‹åˆ†æ", "æ¬¡ä¸–ä»£AIæŠ€è¡“å±•æœ›"
        ]
        
        trends = []
        for i, topic in enumerate(ai_topics):
            trends.append({
                'id': f"aitech-{i}",
                'title': topic,
                'url': 'https://example.com/aitech',
                'source': 'AIæŠ€è¡“å°‚é–€',
                'score': 0,
                'likes': random.randint(35, 180),
                'comments': random.randint(8, 45),
                'published_at': datetime.now().isoformat(),
                'topics': ['AI', 'äººå·¥çŸ¥èƒ½', 'æŠ€è¡“'],
                'description': f"{topic}ã«ã¤ã„ã¦æŠ€è¡“çš„ã«æ·±æ˜ã‚Šã—ã¾ã™",
                'quality_score': random.randint(85, 98)
            })
        
        return trends
    
    async def _get_generative_ai_trends(self) -> List[Dict]:
        """ç”ŸæˆAIé–¢é€£ãƒˆãƒ¬ãƒ³ãƒ‰ç”Ÿæˆ"""
        genai_topics = [
            "ChatGPTæ´»ç”¨äº‹ä¾‹é›†", "Claudeæœ€æ–°æ©Ÿèƒ½è§£èª¬", "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°è¡“",
            "AIç”»åƒç”Ÿæˆãƒ†ã‚¯ãƒ‹ãƒƒã‚¯", "ç”ŸæˆAIãƒ“ã‚¸ãƒã‚¹å¿œç”¨", "RAGå®Ÿè£…ã‚¬ã‚¤ãƒ‰",
            "AIè‡ªå‹•åŒ–ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼", "ç”ŸæˆAIå€«ç†èª²é¡Œ", "AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆæ§‹ç¯‰æ³•"
        ]
        
        trends = []
        for i, topic in enumerate(genai_topics):
            trends.append({
                'id': f"genai-{i}",
                'title': topic,
                'url': 'https://example.com/genai',
                'source': 'ç”ŸæˆAIå°‚é–€',
                'score': 0,
                'likes': random.randint(50, 250),
                'comments': random.randint(12, 60),
                'published_at': datetime.now().isoformat(),
                'topics': ['ç”ŸæˆAI', 'ChatGPT', 'Claude'],
                'description': f"{topic}ã®å®Ÿè·µçš„ãªæ´»ç”¨æ–¹æ³•ã‚’è§£èª¬",
                'quality_score': random.randint(80, 100)
            })
        
        return trends
    
    async def _get_study_trends(self) -> List[Dict]:
        """å‹‰å¼·ãƒ»è‡ªå·±å•“ç™ºé–¢é€£ãƒˆãƒ¬ãƒ³ãƒ‰ç”Ÿæˆ"""
        study_topics = [
            "åŠ¹ç‡çš„å­¦ç¿’æ³•ã®ç§‘å­¦", "ç¿’æ…£åŒ–æˆåŠŸã®ç§˜è¨£", "æ™‚é–“ç®¡ç†è¡“ã®å®Ÿè·µ",
            "ç›®æ¨™è¨­å®šã¨é”æˆæˆ¦ç•¥", "é›†ä¸­åŠ›å‘ä¸Šãƒ†ã‚¯ãƒ‹ãƒƒã‚¯", "è¨˜æ†¶åŠ›å¼·åŒ–ãƒ¡ã‚½ãƒƒãƒ‰",
            "ç¶™ç¶šå­¦ç¿’ã®ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³", "ã‚¹ã‚­ãƒ«ã‚¢ãƒƒãƒ—è¨ˆç”»ç«‹æ¡ˆ", "è‡ªå·±æŠ•è³‡ã®è€ƒãˆæ–¹"
        ]
        
        trends = []
        for i, topic in enumerate(study_topics):
            trends.append({
                'id': f"study-{i}",
                'title': topic,
                'url': 'https://example.com/study',
                'source': 'å­¦ç¿’ãƒ»è‡ªå·±å•“ç™ºå°‚é–€',
                'score': 0,
                'likes': random.randint(20, 100),
                'comments': random.randint(5, 30),
                'published_at': datetime.now().isoformat(),
                'topics': ['å­¦ç¿’', 'è‡ªå·±å•“ç™º', 'æˆé•·'],
                'description': f"{topic}ã«ã¤ã„ã¦ç§‘å­¦çš„æ ¹æ‹ ã«åŸºã¥ã„ã¦è§£èª¬",
                'quality_score': random.randint(65, 90),
                'category': 'å‹‰å¼·ãƒ»è‡ªå·±å•“ç™º'
            })
        
        return trends
    
    async def _get_webdev_trends(self) -> List[Dict]:
        """ã‚¦ã‚§ãƒ–é–‹ç™ºé–¢é€£ãƒˆãƒ¬ãƒ³ãƒ‰ç”Ÿæˆ"""
        webdev_topics = [
            "Reactæœ€æ–°é–‹ç™ºæ‰‹æ³•", "Vue.js 3å®Ÿè·µè¡“", "TypeScriptæ´»ç”¨æ³•",
            "ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰æœ€é©åŒ–", "ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³", "PWAé–‹ç™ºã‚¬ã‚¤ãƒ‰",
            "ã‚¦ã‚§ãƒ–ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£", "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„", "ãƒ¢ãƒ€ãƒ³CSSæŠ€æ³•"
        ]
        
        trends = []
        for i, topic in enumerate(webdev_topics):
            trends.append({
                'id': f"webdev-{i}",
                'title': topic,
                'url': 'https://example.com/webdev',
                'source': 'ã‚¦ã‚§ãƒ–é–‹ç™ºå°‚é–€',
                'score': 0,
                'likes': random.randint(30, 150),
                'comments': random.randint(8, 40),
                'published_at': datetime.now().isoformat(),
                'topics': ['ã‚¦ã‚§ãƒ–é–‹ç™º', 'ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰', 'JavaScript'],
                'description': f"{topic}ã®æœ€æ–°å‹•å‘ã¨å®Ÿè£…æ–¹æ³•ã‚’ç´¹ä»‹",
                'quality_score': random.randint(70, 95)
            })
        
        return trends

if __name__ == "__main__":
    asyncio.run(demo_enhanced_trends())