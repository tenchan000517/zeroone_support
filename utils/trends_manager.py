# -*- coding:utf-8 -*-
import aiohttp
import xml.etree.ElementTree as ET
import datetime
from typing import List, Dict, Optional
import asyncio
import re

class TrendsManager:
    def __init__(self):
        self.daily_trends_url = "https://trends.google.co.jp/trends/trendingsearches/daily/rss?geo=JP"
        self.realtime_trends_url = "https://trends.google.co.jp/trends/trendingsearches/realtime/rss?geo=JP"
        
        # ãƒ“ã‚¸ãƒã‚¹é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ç”¨ï¼‰
        self.business_keywords = [
            "çµŒæ¸ˆ", "ãƒ“ã‚¸ãƒã‚¹", "ä¼æ¥­", "æ ªå¼", "æŠ•è³‡", "å¸‚å ´", "çµŒå–¶", "å£²ä¸Š", "åˆ©ç›Š",
            "M&A", "IPO", "æ±ºç®—", "æ¥­ç¸¾", "AI", "DX", "IT", "ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼", "ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³",
            "ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—", "èµ·æ¥­", "å‰¯æ¥­", "è»¢è·", "ã‚­ãƒ£ãƒªã‚¢", "åƒãæ–¹", "ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯",
            "ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°", "ãƒ–ãƒ©ãƒ³ãƒ‰", "EC", "eã‚³ãƒãƒ¼ã‚¹", "ãƒ‡ã‚¸ã‚¿ãƒ«", "ãƒ‡ãƒ¼ã‚¿åˆ†æ",
            "ä»®æƒ³é€šè²¨", "ãƒ–ãƒ­ãƒƒã‚¯ãƒã‚§ãƒ¼ãƒ³", "NFT", "ãƒ¡ã‚¿ãƒãƒ¼ã‚¹", "ã‚µã‚¹ãƒ†ãƒŠãƒ“ãƒªãƒ†ã‚£",
            "ESG", "SDGs", "ã‚°ãƒªãƒ¼ãƒ³", "ã‚«ãƒ¼ãƒœãƒ³"
        ]
    
    async def get_business_trends(self, max_trends: int = 5) -> List[Dict]:
        """ãƒ“ã‚¸ãƒã‚¹é–¢é€£ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’å–å¾—"""
        all_trends = []
        
        # ãƒ‡ã‚¤ãƒªãƒ¼ãƒˆãƒ¬ãƒ³ãƒ‰ã¨ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒˆãƒ¬ãƒ³ãƒ‰ã®ä¸¡æ–¹ã‚’å–å¾—
        daily_trends = await self._fetch_trends(self.daily_trends_url, "daily")
        realtime_trends = await self._fetch_trends(self.realtime_trends_url, "realtime")
        
        all_trends.extend(daily_trends)
        all_trends.extend(realtime_trends)
        
        # ãƒ“ã‚¸ãƒã‚¹é–¢é€£ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        business_trends = self._filter_business_trends(all_trends)
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šãƒ“ã‚¸ãƒã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰ãŒå°‘ãªã„å ´åˆã¯ä¸€èˆ¬çš„ãªãƒˆãƒ¬ãƒ³ãƒ‰ã‚‚å«ã‚ã‚‹
        if len(business_trends) < 3:
            business_trends.extend(all_trends[:max_trends - len(business_trends)])
        
        # é‡è¤‡é™¤å»
        unique_trends = self._remove_duplicates(business_trends)
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ããªã„å ´åˆ
        if not unique_trends:
            unique_trends = self._get_fallback_trends()
        
        return unique_trends[:max_trends]
    
    async def _fetch_trends(self, url: str, trend_type: str) -> List[Dict]:
        """æŒ‡å®šã•ã‚ŒãŸURLã‹ã‚‰ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’å–å¾—"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    url,
                    headers={
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                        'Accept-Language': 'ja,en;q=0.9'
                    },
                    timeout=aiohttp.ClientTimeout(total=15)
                ) as response:
                    if response.status == 200:
                        content = await response.text()
                        return self._parse_rss(content, trend_type)
                    else:
                        print(f"Failed to fetch {trend_type} trends: {response.status}")
                        return []
        except Exception as e:
            print(f"Error fetching {trend_type} trends: {e}")
            return []
    
    def _parse_rss(self, rss_content: str, trend_type: str) -> List[Dict]:
        """RSS XMLã‚’è§£æã—ã¦ãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±ã‚’æŠ½å‡º"""
        trends = []
        
        try:
            root = ET.fromstring(rss_content)
            
            # RSSåå‰ç©ºé–“ã®å‡¦ç†
            items = root.findall('.//item')
            
            for item in items:
                title = item.find('title')
                description = item.find('description')
                pub_date = item.find('pubDate')
                link = item.find('link')
                
                if title is not None:
                    trend_title = title.text or ""
                    
                    # èª¬æ˜æ–‡ã‹ã‚‰ã‚ˆã‚Šè©³ç´°ãªæƒ…å ±ã‚’æŠ½å‡º
                    trend_description = ""
                    if description is not None and description.text:
                        # HTMLã‚¿ã‚°ã‚’é™¤å»
                        clean_desc = re.sub(r'<[^>]+>', '', description.text)
                        trend_description = clean_desc.strip()
                    
                    # æ—¥æ™‚æƒ…å ±
                    trend_date = ""
                    if pub_date is not None and pub_date.text:
                        trend_date = pub_date.text
                    
                    # ãƒªãƒ³ã‚¯æƒ…å ±
                    trend_link = ""
                    if link is not None and link.text:
                        trend_link = link.text
                    
                    trends.append({
                        'title': trend_title,
                        'description': trend_description,
                        'date': trend_date,
                        'link': trend_link,
                        'type': trend_type,
                        'category': self._categorize_trend(trend_title + " " + trend_description)
                    })
            
        except ET.ParseError as e:
            print(f"XML parsing error: {e}")
        except Exception as e:
            print(f"Error parsing RSS: {e}")
        
        return trends
    
    def _filter_business_trends(self, trends: List[Dict]) -> List[Dict]:
        """ãƒ“ã‚¸ãƒã‚¹é–¢é€£ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"""
        business_trends = []
        
        for trend in trends:
            text = (trend['title'] + " " + trend['description']).lower()
            
            # ãƒ“ã‚¸ãƒã‚¹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if any(keyword in text for keyword in self.business_keywords):
                business_trends.append(trend)
        
        return business_trends
    
    def _categorize_trend(self, text: str) -> str:
        """ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’ã‚«ãƒ†ã‚´ãƒªåˆ†ã‘ã™ã‚‹"""
        text_lower = text.lower()
        
        if any(word in text_lower for word in ["ai", "äººå·¥çŸ¥èƒ½", "æ©Ÿæ¢°å­¦ç¿’", "dx", "ãƒ‡ã‚¸ã‚¿ãƒ«"]):
            return "ğŸ¤– AIãƒ»ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼"
        elif any(word in text_lower for word in ["æŠ•è³‡", "æ ªå¼", "å¸‚å ´", "çµŒæ¸ˆ", "é‡‘è"]):
            return "ğŸ’° çµŒæ¸ˆãƒ»æŠ•è³‡"
        elif any(word in text_lower for word in ["åƒãæ–¹", "è»¢è·", "ã‚­ãƒ£ãƒªã‚¢", "ãƒªãƒ¢ãƒ¼ãƒˆ"]):
            return "ğŸ’¼ åƒãæ–¹ãƒ»ã‚­ãƒ£ãƒªã‚¢"
        elif any(word in text_lower for word in ["ä¼æ¥­", "çµŒå–¶", "ãƒ“ã‚¸ãƒã‚¹", "å£²ä¸Š", "æ±ºç®—"]):
            return "ğŸ¢ ä¼æ¥­ãƒ»çµŒå–¶"
        elif any(word in text_lower for word in ["esg", "ã‚µã‚¹ãƒ†ãƒŠ", "ç’°å¢ƒ", "ã‚°ãƒªãƒ¼ãƒ³"]):
            return "ğŸŒ± ã‚µã‚¹ãƒ†ãƒŠãƒ“ãƒªãƒ†ã‚£"
        else:
            return "ğŸ“Š ä¸€èˆ¬ãƒˆãƒ¬ãƒ³ãƒ‰"
    
    def _remove_duplicates(self, trends: List[Dict]) -> List[Dict]:
        """é‡è¤‡ã™ã‚‹ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’é™¤å»"""
        seen_titles = set()
        unique_trends = []
        
        for trend in trends:
            title_lower = trend['title'].lower()
            if title_lower not in seen_titles:
                seen_titles.add(title_lower)
                unique_trends.append(trend)
        
        return unique_trends
    
    def _get_fallback_trends(self) -> List[Dict]:
        """APIåˆ©ç”¨ä¸å¯æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒˆãƒ¬ãƒ³ãƒ‰"""
        today = datetime.datetime.now()
        
        fallback_trends = [
            {
                'title': 'AIæŠ€è¡“ã®ä¼æ¥­å°å…¥ãŒåŠ é€Ÿ',
                'description': 'ç”ŸæˆAIãƒ„ãƒ¼ãƒ«ã‚’æ´»ç”¨ã—ãŸæ¥­å‹™åŠ¹ç‡åŒ–ãŒå¤šãã®ä¼æ¥­ã§å°å…¥ã•ã‚Œã¦ã„ã¾ã™',
                'date': today.strftime('%a, %d %b %Y %H:%M:%S +0900'),
                'link': 'https://trends.google.co.jp',
                'type': 'fallback',
                'category': 'ğŸ¤– AIãƒ»ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼'
            },
            {
                'title': 'ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯é–¢é€£ã‚µãƒ¼ãƒ“ã‚¹ã®éœ€è¦å¢—',
                'description': 'ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¯ãƒ¼ã‚¯ã®å®šç€ã«ã‚ˆã‚Šã€é–¢é€£ãƒ„ãƒ¼ãƒ«ã‚„ã‚µãƒ¼ãƒ“ã‚¹ã¸ã®æ³¨ç›®ãŒé«˜ã¾ã£ã¦ã„ã¾ã™',
                'date': today.strftime('%a, %d %b %Y %H:%M:%S +0900'),
                'link': 'https://trends.google.co.jp',
                'type': 'fallback',
                'category': 'ğŸ’¼ åƒãæ–¹ãƒ»ã‚­ãƒ£ãƒªã‚¢'
            },
            {
                'title': 'ã‚µã‚¹ãƒ†ãƒŠãƒ“ãƒªãƒ†ã‚£æŠ•è³‡ã«æ³¨ç›®',
                'description': 'ESGæŠ•è³‡ã¸ã®é–¢å¿ƒãŒé«˜ã¾ã‚Šã€ä¼æ¥­ã®ç’°å¢ƒé…æ…®ãŒæŠ•è³‡åˆ¤æ–­ã®é‡è¦è¦ç´ ã«ãªã£ã¦ã„ã¾ã™',
                'date': today.strftime('%a, %d %b %Y %H:%M:%S +0900'),
                'link': 'https://trends.google.co.jp',
                'type': 'fallback',
                'category': 'ğŸŒ± ã‚µã‚¹ãƒ†ãƒŠãƒ“ãƒªãƒ†ã‚£'
            }
        ]
        
        return fallback_trends
    
    def format_trends_for_embed(self, trends: List[Dict]) -> Dict:
        """ãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±ã‚’Embedç”¨ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        if not trends:
            return {
                "title": "ğŸ“Š ãƒ“ã‚¸ãƒã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰é€Ÿå ±",
                "description": "**GoogleTrends**ã‹ã‚‰æœ€æ–°ã®ãƒ“ã‚¸ãƒã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’ãŠå±Šã‘ã—ã¾ã™ï¼",
                "fields": [
                    {
                        "name": "ğŸ“ˆ ä»Šæ—¥ã®ãƒˆãƒ¬ãƒ³ãƒ‰",
                        "value": "ç¾åœ¨ãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚\nå¾Œã»ã©å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚",
                        "inline": False
                    }
                ],
                "color": 0x9C27B0
            }
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±ã‚’æ•´å½¢ï¼ˆDiscord 1024æ–‡å­—åˆ¶é™å¯¾å¿œï¼‰
        trend_list = []
        total_length = 0
        max_field_length = 900
        
        for i, trend in enumerate(trends[:3], 1):  # æœ€å¤§3ä»¶è¡¨ç¤º
            try:
                title = trend['title']
                if len(title) > 30:
                    title = title[:27] + "..."
                
                description = trend.get('description', '')
                if description and len(description) > 50:
                    description = description[:47] + "..."
                
                category = trend.get('category', 'ğŸ“Š ä¸€èˆ¬ãƒˆãƒ¬ãƒ³ãƒ‰')
                
                trend_info = f"**{category}**\nğŸ”¥ {title}"
                
                if description:
                    trend_info += f"\nğŸ’­ {description}"
                
                if trend.get('link') and 'google' in trend['link']:
                    trend_info += f"\nğŸ”— [è©³ç´°ã‚’è¦‹ã‚‹]({trend['link']})"
                
                # æ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯
                if total_length + len(trend_info) + 2 > max_field_length:
                    break
                
                trend_list.append(trend_info)
                total_length += len(trend_info) + 2
                
            except Exception as e:
                print(f"Error formatting trend: {e}")
                continue
        
        return {
            "title": "ğŸ“Š ãƒ“ã‚¸ãƒã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰é€Ÿå ±",
            "description": "**GoogleTrends**ã‹ã‚‰å³é¸ã—ãŸæœ€æ–°ãƒ“ã‚¸ãƒã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’ãŠå±Šã‘ï¼\nå¸‚å ´ã®å‹•ãã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ã‚­ãƒ£ãƒƒãƒâœ¨",
            "fields": [
                {
                    "name": "ğŸ”¥ æ³¨ç›®ã®ãƒˆãƒ¬ãƒ³ãƒ‰",
                    "value": "\n\n".join(trend_list) if trend_list else "ãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ",
                    "inline": False
                },
                {
                    "name": "ğŸ’¡ ãƒˆãƒ¬ãƒ³ãƒ‰æ´»ç”¨ã®ãƒ’ãƒ³ãƒˆ",
                    "value": "â€¢ å¸‚å ´ã®å¤‰åŒ–ã‚’ã„ã¡æ—©ãã‚­ãƒ£ãƒƒãƒ\nâ€¢ é¡§å®¢ãƒ‹ãƒ¼ã‚ºã®å¤‰å‹•ã‚’æŠŠæ¡\nâ€¢ æ–°ã—ã„ãƒ“ã‚¸ãƒã‚¹æ©Ÿä¼šã‚’ç™ºè¦‹\nâ€¢ ç«¶åˆä»–ç¤¾ã®å‹•å‘ã‚’ç›£è¦–",
                    "inline": False
                }
            ],
            "color": 0x9C27B0,
            "footer": {
                "text": "ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: Google Trends Japan | ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’å…ˆå–ã‚Šã—ã¦ç«¶äº‰å„ªä½ã‚’ç¯‰ã“ã†"
            }
        }