# -*- coding:utf-8 -*-
"""
Enhanced Trends Manager - Fixed Version
é«˜å“è³ªãªãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚·ã‚¹ãƒ†ãƒ ï¼ˆ7ã‚«ãƒ†ã‚´ãƒªå…¨è¡¨ç¤ºå¯¾å¿œï¼‰

ä¿®æ­£ç‚¹:
- é‡è¤‡è¨˜äº‹é™¤å»æ©Ÿèƒ½è¿½åŠ 
- å„ã‚«ãƒ†ã‚´ãƒªã«é©åˆ‡ãªcategoryãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰è¨­å®š
- 7ã‚«ãƒ†ã‚´ãƒªå¼·åˆ¶è¡¨ç¤ºãƒ­ã‚¸ãƒƒã‚¯å®Ÿè£…
- Discordç”¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®æ”¹å–„
"""

import aiohttp
import asyncio
import json
import xml.etree.ElementTree as ET
import re
from typing import List, Dict, Optional
from datetime import datetime
import random

class EnhancedTrendsManager:
    def __init__(self):
        self.session = None
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è¾æ›¸
        self.category_keywords = {
            'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°': [
                'programming', 'code', 'coding', 'algorithm', 'data structure', 
                'clean code', 'refactoring', 'software engineering', 'design pattern',
                'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°', 'ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ', 'ãƒ‡ãƒ¼ã‚¿æ§‹é€ ', 'ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢å·¥å­¦',
                'python', 'rust', 'go', 'java', 'c++', 'c#', 'kotlin', 'swift',
                'ruby', 'php', 'scala', 'dart', 'node.js', 'express', 'django',
                'github', 'git', 'oss', 'ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹', 'é–‹ç™ºè€…', 'ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢', 'developer',
                'api', 'ãƒ©ã‚¤ãƒ–ãƒ©ãƒª', 'ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯', 'ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ', 'template',
                'ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰', 'backend', 'ãƒ•ãƒ«ã‚¹ã‚¿ãƒƒã‚¯', 'fullstack', 'ãƒ‡ãƒãƒƒã‚°', 'debug'
            ],
            'ã‚¦ã‚§ãƒ–é–‹ç™º': [
                'javascript', 'typescript', 'es6', 'es2024', 'vanilla js',
                'frontend', 'web development', 'html', 'css', 'sass', 'tailwind',
                'ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰', 'ã‚¦ã‚§ãƒ–é–‹ç™º', 'ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆåˆ¶ä½œ',
                'react', 'vue', 'angular', 'svelte', 'next.js', 'nuxt', 'gatsby',
                'react native', 'vue3', 'react hooks', 'vue composition',
                'css grid', 'flexbox', 'css modules', 'styled components',
                'pwa', 'spa', 'ssr', 'ssg', 'jamstack',
                'stripe', 'payment', 'æ±ºæ¸ˆ', 'discord', 'bot', 'ã‚¦ã‚§ãƒ–ã‚¢ãƒ—ãƒª', 'webapp',
                'crud', 'rest', 'graphql', 'json', 'ajax', 'axios', 'fetch'
            ],
            'ç”ŸæˆAI': [
                'chatgpt', 'claude', 'gemini', 'copilot', 'stable diffusion', 'midjourney',
                'dall-e', 'openai', 'anthropic', 'google ai', 'microsoft copilot',
                'prompt engineering', 'prompt design', 'ai writing', 'ai art',
                'ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ', 'ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°', 'AIæ´»ç”¨', 'AIåˆ©ç”¨',
                'ai automation', 'ai workflow', 'ai productivity', 'ai assistant',
                'AIè‡ªå‹•åŒ–', 'AIåŠ¹ç‡åŒ–', 'AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ', 'AIå°å…¥',
                'text generation', 'image generation', 'code generation', 'ai chat',
                'rag', 'retrieval augmented generation', 'few-shot', 'zero-shot'
            ],
            'ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ãƒ»AIé–‹ç™º': [
                'ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹', 'ãƒ‡ãƒ¼ã‚¿åˆ†æ', 'pandas', 'çµ±è¨ˆ', 'å¯è¦–åŒ–', 'äºˆæ¸¬',
                'data science', 'data analysis', 'statistics', 'visualization',
                'big data', 'ãƒ“ãƒƒã‚°ãƒ‡ãƒ¼ã‚¿', 'ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ‹ãƒ³ã‚°', 'analytics',
                'jupyter', 'notebook', 'matplotlib', 'seaborn', 'plotly',
                'machine learning', 'deep learning', 'neural network', 'ai model'
            ],
            'ã‚­ãƒ£ãƒªã‚¢': [
                'ã‚­ãƒ£ãƒªã‚¢', 'è»¢è·', 'ã‚¹ã‚­ãƒ«', 'å¹´å', 'é¢æ¥', 'å±¥æ­´æ›¸', 'æˆé•·',
                'career', 'job change', 'skill', 'salary', 'interview', 'resume',
                'ãƒ•ãƒªãƒ¼ãƒ©ãƒ³ã‚¹', 'ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯', 'å‰¯æ¥­', 'ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢è»¢è·',
                'å€‹äººé–‹ç™º', 'å€‹äººé–‹ç™ºè€…', 'ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª', 'portfolio', 'èµ·æ¥­', 'startup',
                'ç‹¬ç«‹', 'freelance', 'work', 'åƒãæ–¹', 'work-life', 'ãƒ¯ãƒ¼ã‚¯ãƒ©ã‚¤ãƒ•'
            ],
            'ãƒ“ã‚¸ãƒã‚¹': [
                'ãƒ“ã‚¸ãƒã‚¹', 'æˆ¦ç•¥', 'ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°', 'å£²ä¸Š', 'æˆé•·', 'ROI', 'KPI',
                'business', 'strategy', 'marketing', 'sales', 'growth',
                'ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—', 'DX', 'ãƒ‡ã‚¸ã‚¿ãƒ«å¤‰é©', 'ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³'
            ],
            'å‹‰å¼·ãƒ»è‡ªå·±å•“ç™º': [
                'å­¦ç¿’', 'å‹‰å¼·', 'ã‚¹ã‚­ãƒ«ã‚¢ãƒƒãƒ—', 'æˆé•·', 'ç¿’æ…£', 'åŠ¹ç‡', 'ç¶™ç¶š',
                'learning', 'study', 'skill up', 'growth', 'habit', 'efficiency'
            ]
        }
    
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def get_enhanced_trends(self, max_trends: int = 200, categories: List[str] = None) -> List[Dict]:
        """é«˜å“è³ªãªãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        try:
            all_trends = []
            
            # 1. Zennè¨˜äº‹å–å¾—
            zenn_trends = await self._get_zenn_trends()
            all_trends.extend(zenn_trends)
            
            # 2. ã‚«ãƒ†ã‚´ãƒªåˆ¥å°‚é–€ãƒˆãƒ¬ãƒ³ãƒ‰å–å¾—ï¼ˆcategoryãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ä»˜ãï¼‰
            career_trends = await self._get_career_trends()
            all_trends.extend(career_trends)
            
            business_trends = await self._get_business_trends()
            all_trends.extend(business_trends)
            
            programming_trends = await self._get_programming_trends()
            all_trends.extend(programming_trends)
            
            data_science_trends = await self._get_data_science_trends()
            all_trends.extend(data_science_trends)
            
            generative_ai_trends = await self._get_generative_ai_trends()
            all_trends.extend(generative_ai_trends)
            
            study_trends = await self._get_study_trends()
            all_trends.extend(study_trends)
            
            webdev_trends = await self._get_webdev_trends()
            all_trends.extend(webdev_trends)
            
            # è‡ªå‹•ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ï¼ˆcategoryãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒãªã„è¨˜äº‹ã®ã¿ï¼‰
            categorized_trends = self._categorize_trends(all_trends)
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆæŒ‡å®šã‚«ãƒ†ã‚´ãƒªãŒã‚ã‚‹å ´åˆï¼‰
            if categories:
                filtered_trends = []
                for trend in categorized_trends:
                    if trend.get('category') in categories:
                        filtered_trends.append(trend)
                categorized_trends = filtered_trends
            
            # å“è³ªã‚¹ã‚³ã‚¢é †ã§ã‚½ãƒ¼ãƒˆ
            sorted_trends = sorted(categorized_trends, key=lambda x: x.get('quality_score', 0), reverse=True)
            
            return sorted_trends[:max_trends]
            
        except Exception as e:
            print(f"Enhanced trendså–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return self._get_fallback_trends()
    
    async def _get_zenn_trends(self) -> List[Dict]:
        """Zenn API ã‹ã‚‰æŠ€è¡“è¨˜äº‹ã‚’å–å¾—"""
        trends = []
        endpoints = [
            'https://zenn.dev/api/articles?order=liked_count&count=50',
            'https://zenn.dev/api/articles?order=trending&count=30'
        ]
        
        for endpoint in endpoints:
            try:
                async with self.session.get(endpoint, timeout=10) as response:
                    if response.status == 200:
                        data = await response.json()
                        if data.get('articles'):
                            for article in data['articles']:
                                if article.get('liked_count', 0) > 10:
                                    trends.append({
                                        'id': f"zenn-{article.get('id')}",
                                        'title': article.get('title', ''),
                                        'url': f"https://zenn.dev{article.get('path', '')}",
                                        'source': 'Zenn',
                                        'score': 0,
                                        'likes': article.get('liked_count', 0),
                                        'comments': article.get('comments_count', 0),
                                        'published_at': article.get('published_at', ''),
                                        'topics': [t.get('name', '') for t in article.get('topics', [])],
                                        'description': self._generate_summary(article.get('title', '')),
                                        'quality_score': min(article.get('liked_count', 0), 100)
                                    })
                await asyncio.sleep(0.5)
            except Exception as e:
                print(f"Zenn API ã‚¨ãƒ©ãƒ¼: {e}")
        
        return trends
    
    def _categorize_trends(self, trends: List[Dict]) -> List[Dict]:
        """ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è‡ªå‹•ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ï¼ˆcategoryãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒãªã„è¨˜äº‹ã®ã¿ï¼‰"""
        for trend in trends:
            # æ—¢ã«categoryãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            if trend.get('category'):
                continue
                
            title_text = trend.get('title', '').lower()
            description_text = trend.get('description', '').lower()
            combined_text = f"{title_text} {description_text}"
            
            # ã‚«ãƒ†ã‚´ãƒªåˆ¤å®š
            category = 'ä¸€èˆ¬'
            max_matches = 0
            
            for cat, keywords in self.category_keywords.items():
                matches = sum(1 for keyword in keywords if keyword.lower() in combined_text)
                if matches > max_matches:
                    max_matches = matches
                    category = cat
            
            trend['category'] = category
            trend['category_confidence'] = max_matches
        
        return trends
    
    def _generate_summary(self, title: str) -> str:
        """ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ç°¡æ˜“è¦ç´„ã‚’ç”Ÿæˆ"""
        clean_title = re.sub(r'\s*-\s*[^-]*$', '', title)
        if len(clean_title) > 100:
            clean_title = clean_title[:97] + "..."
        return clean_title
    
    async def _get_career_trends(self) -> List[Dict]:
        """ã‚­ãƒ£ãƒªã‚¢é–¢é€£ãƒˆãƒ¬ãƒ³ãƒ‰ç”Ÿæˆ"""
        career_topics = [
            "è»¢è·å¸‚å ´ã®æœ€æ–°å‹•å‘", "ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ã®ã‚­ãƒ£ãƒªã‚¢æˆ¦ç•¥", "ã‚¹ã‚­ãƒ«ã‚¢ãƒƒãƒ—ã®ãƒã‚¤ãƒ³ãƒˆ",
            "é¢æ¥å¯¾ç­–ã®ã‚³ãƒ„", "å±¥æ­´æ›¸ã®æ›¸ãæ–¹", "ã‚­ãƒ£ãƒªã‚¢ãƒã‚§ãƒ³ã‚¸æˆåŠŸäº‹ä¾‹",
            "ãƒ•ãƒªãƒ¼ãƒ©ãƒ³ã‚¹è»¢å‘ã®æº–å‚™", "å¹´åã‚¢ãƒƒãƒ—ã®æ–¹æ³•", "ãƒ¯ãƒ¼ã‚¯ãƒ©ã‚¤ãƒ•ãƒãƒ©ãƒ³ã‚¹"
        ]
        
        trends = []
        for i, topic in enumerate(career_topics):
            trends.append({
                'id': f"career-{i}",
                'title': topic,
                'url': 'https://example.com/career',
                'source': 'ã‚­ãƒ£ãƒªã‚¢å°‚é–€',
                'score': 0,
                'likes': random.randint(20, 100),
                'comments': random.randint(5, 30),
                'published_at': datetime.now().isoformat(),
                'topics': ['ã‚­ãƒ£ãƒªã‚¢', 'è»¢è·', 'ã‚¹ã‚­ãƒ«'],
                'description': f"{topic}ã«ã¤ã„ã¦è©³ã—ãè§£èª¬ã—ã¾ã™",
                'quality_score': random.randint(60, 90),
                'category': 'ã‚­ãƒ£ãƒªã‚¢'  # æ˜ç¤ºçš„ã«ã‚«ãƒ†ã‚´ãƒªã‚’è¨­å®š
            })
        
        return trends
    
    async def _get_business_trends(self) -> List[Dict]:
        """ãƒ“ã‚¸ãƒã‚¹é–¢é€£ãƒˆãƒ¬ãƒ³ãƒ‰ç”Ÿæˆ"""
        business_topics = [
            "DXæ¨é€²ã®æœ€æ–°äº‹ä¾‹", "ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°æˆ¦ç•¥ã®é©æ–°", "ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—æŠ•è³‡å‹•å‘",
            "åƒãæ–¹æ”¹é©ã®æˆåŠŸä¾‹", "ãƒ‡ã‚¸ã‚¿ãƒ«ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°æ‰‹æ³•", "äº‹æ¥­æˆé•·ã®KPIè¨­è¨ˆ",
            "é¡§å®¢æº€è¶³åº¦å‘ä¸Šæ–½ç­–", "çµ„ç¹”ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆè¡“", "ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³å‰µå‡ºæ³•"
        ]
        
        trends = []
        for i, topic in enumerate(business_topics):
            trends.append({
                'id': f"business-{i}",
                'title': topic,
                'url': 'https://example.com/business',
                'source': 'ãƒ“ã‚¸ãƒã‚¹å°‚é–€',
                'score': 0,
                'likes': random.randint(30, 150),
                'comments': random.randint(8, 40),
                'published_at': datetime.now().isoformat(),
                'topics': ['ãƒ“ã‚¸ãƒã‚¹', 'æˆ¦ç•¥', 'DX'],
                'description': f"{topic}ã®è©³ç´°åˆ†æã‚’ãŠå±Šã‘ã—ã¾ã™",
                'quality_score': random.randint(70, 95),
                'category': 'ãƒ“ã‚¸ãƒã‚¹'
            })
        
        return trends
    
    async def _get_programming_trends(self) -> List[Dict]:
        """ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°é–¢é€£ãƒˆãƒ¬ãƒ³ãƒ‰ç”Ÿæˆ"""
        programming_topics = [
            "æœ€æ–°Pythoné–‹ç™ºæ‰‹æ³•", "JavaScript ES2024æ–°æ©Ÿèƒ½", "Rustè¨€èªã®æ´»ç”¨äº‹ä¾‹",
            "ã‚¯ãƒªãƒ¼ãƒ³ã‚³ãƒ¼ãƒ‰å®Ÿè·µè¡“", "ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æœ€é©åŒ–", "APIè¨­è¨ˆãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹",
            "ãƒ‡ãƒãƒƒã‚°åŠ¹ç‡åŒ–ãƒ„ãƒ¼ãƒ«", "ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã‚³ãƒ„", "é–‹ç™ºãƒãƒ¼ãƒ é‹å–¶æ³•"
        ]
        
        trends = []
        for i, topic in enumerate(programming_topics):
            trends.append({
                'id': f"programming-{i}",
                'title': topic,
                'url': 'https://example.com/programming',
                'source': 'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å°‚é–€',
                'score': 0,
                'likes': random.randint(40, 200),
                'comments': random.randint(10, 50),
                'published_at': datetime.now().isoformat(),
                'topics': ['ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°', 'ã‚³ãƒ¼ãƒ‰', 'é–‹ç™º'],
                'description': f"{topic}ã«ã¤ã„ã¦å®Ÿè·µçš„ã«è§£èª¬ã—ã¾ã™",
                'quality_score': random.randint(75, 98),
                'category': 'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°'
            })
        
        return trends
    
    async def _get_data_science_trends(self) -> List[Dict]:
        """ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹é–¢é€£ãƒˆãƒ¬ãƒ³ãƒ‰ç”Ÿæˆ"""
        ds_topics = [
            "æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«æœ€é©åŒ–", "ãƒ‡ãƒ¼ã‚¿åˆ†ææ‰‹æ³•ã®æ¯”è¼ƒ", "ãƒ“ãƒƒã‚°ãƒ‡ãƒ¼ã‚¿å‡¦ç†æŠ€è¡“",
            "AIäºˆæ¸¬ç²¾åº¦å‘ä¸Šæ³•", "ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–ã®ã‚³ãƒ„", "çµ±è¨ˆè§£æã®å®Ÿå‹™å¿œç”¨",
            "MLOpså®Ÿè£…ã‚¬ã‚¤ãƒ‰", "ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­è¨ˆ", "åˆ†æçµæœã®è§£é‡ˆæ–¹æ³•"
        ]
        
        trends = []
        for i, topic in enumerate(ds_topics):
            trends.append({
                'id': f"datascience-{i}",
                'title': topic,
                'url': 'https://example.com/datascience',
                'source': 'ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹å°‚é–€',
                'score': 0,
                'likes': random.randint(25, 120),
                'comments': random.randint(6, 35),
                'published_at': datetime.now().isoformat(),
                'topics': ['ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹', 'æ©Ÿæ¢°å­¦ç¿’', 'AI'],
                'description': f"{topic}ã®å®Ÿè·µçš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ç´¹ä»‹",
                'quality_score': random.randint(80, 95),
                'category': 'ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ãƒ»AIé–‹ç™º'
            })
        
        return trends
    
    async def _get_generative_ai_trends(self) -> List[Dict]:
        """ç”ŸæˆAIé–¢é€£ãƒˆãƒ¬ãƒ³ãƒ‰ç”Ÿæˆ"""
        genai_topics = [
            "ChatGPTæ´»ç”¨äº‹ä¾‹é›†", "Claudeæœ€æ–°æ©Ÿèƒ½è§£èª¬", "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°è¡“",
            "AIç”»åƒç”Ÿæˆãƒ†ã‚¯ãƒ‹ãƒƒã‚¯", "ç”ŸæˆAIãƒ“ã‚¸ãƒã‚¹å¿œç”¨", "RAGå®Ÿè£…ã‚¬ã‚¤ãƒ‰",
            "AIè‡ªå‹•åŒ–ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼", "ç”ŸæˆAIå€«ç†èª²é¡Œ", "AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆæ§‹ç¯‰æ³•"
        ]
        
        trends = []
        for i, topic in enumerate(genai_topics):
            trends.append({
                'id': f"genai-{i}",
                'title': topic,
                'url': 'https://example.com/genai',
                'source': 'ç”ŸæˆAIå°‚é–€',
                'score': 0,
                'likes': random.randint(50, 250),
                'comments': random.randint(12, 60),
                'published_at': datetime.now().isoformat(),
                'topics': ['ç”ŸæˆAI', 'ChatGPT', 'Claude'],
                'description': f"{topic}ã®å®Ÿè·µçš„ãªæ´»ç”¨æ–¹æ³•ã‚’è§£èª¬",
                'quality_score': random.randint(80, 100),
                'category': 'ç”ŸæˆAI'
            })
        
        return trends
    
    async def _get_study_trends(self) -> List[Dict]:
        """å‹‰å¼·ãƒ»è‡ªå·±å•“ç™ºé–¢é€£ãƒˆãƒ¬ãƒ³ãƒ‰ç”Ÿæˆ"""
        study_topics = [
            "åŠ¹ç‡çš„å­¦ç¿’æ³•ã®ç§‘å­¦", "ç¿’æ…£åŒ–æˆåŠŸã®ç§˜è¨£", "æ™‚é–“ç®¡ç†è¡“ã®å®Ÿè·µ",
            "ç›®æ¨™è¨­å®šã¨é”æˆæˆ¦ç•¥", "é›†ä¸­åŠ›å‘ä¸Šãƒ†ã‚¯ãƒ‹ãƒƒã‚¯", "è¨˜æ†¶åŠ›å¼·åŒ–ãƒ¡ã‚½ãƒƒãƒ‰",
            "ç¶™ç¶šå­¦ç¿’ã®ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³", "ã‚¹ã‚­ãƒ«ã‚¢ãƒƒãƒ—è¨ˆç”»ç«‹æ¡ˆ", "è‡ªå·±æŠ•è³‡ã®è€ƒãˆæ–¹"
        ]
        
        trends = []
        for i, topic in enumerate(study_topics):
            trends.append({
                'id': f"study-{i}",
                'title': topic,
                'url': 'https://example.com/study',
                'source': 'å­¦ç¿’ãƒ»è‡ªå·±å•“ç™ºå°‚é–€',
                'score': 0,
                'likes': random.randint(20, 100),
                'comments': random.randint(5, 30),
                'published_at': datetime.now().isoformat(),
                'topics': ['å­¦ç¿’', 'è‡ªå·±å•“ç™º', 'æˆé•·'],
                'description': f"{topic}ã«ã¤ã„ã¦ç§‘å­¦çš„æ ¹æ‹ ã«åŸºã¥ã„ã¦è§£èª¬",
                'quality_score': random.randint(65, 90),
                'category': 'å‹‰å¼·ãƒ»è‡ªå·±å•“ç™º'
            })
        
        return trends
    
    async def _get_webdev_trends(self) -> List[Dict]:
        """ã‚¦ã‚§ãƒ–é–‹ç™ºé–¢é€£ãƒˆãƒ¬ãƒ³ãƒ‰ç”Ÿæˆ"""
        webdev_topics = [
            "Reactæœ€æ–°é–‹ç™ºæ‰‹æ³•", "Vue.js 3å®Ÿè·µè¡“", "TypeScriptæ´»ç”¨æ³•",
            "ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰æœ€é©åŒ–", "ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³", "PWAé–‹ç™ºã‚¬ã‚¤ãƒ‰",
            "ã‚¦ã‚§ãƒ–ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£", "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„", "ãƒ¢ãƒ€ãƒ³CSSæŠ€æ³•"
        ]
        
        trends = []
        for i, topic in enumerate(webdev_topics):
            trends.append({
                'id': f"webdev-{i}",
                'title': topic,
                'url': 'https://example.com/webdev',
                'source': 'ã‚¦ã‚§ãƒ–é–‹ç™ºå°‚é–€',
                'score': 0,
                'likes': random.randint(30, 150),
                'comments': random.randint(8, 40),
                'published_at': datetime.now().isoformat(),
                'topics': ['ã‚¦ã‚§ãƒ–é–‹ç™º', 'ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰', 'JavaScript'],
                'description': f"{topic}ã®æœ€æ–°å‹•å‘ã¨å®Ÿè£…æ–¹æ³•ã‚’ç´¹ä»‹",
                'quality_score': random.randint(70, 95),
                'category': 'ã‚¦ã‚§ãƒ–é–‹ç™º'
            })
        
        return trends

    def _get_fallback_trends(self) -> List[Dict]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿"""
        return [
            {
                'id': 'fallback-1',
                'title': 'Claude Code ã®æ´»ç”¨æ–¹æ³•ãŒè©±é¡Œ',
                'url': 'https://example.com',
                'source': 'ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯',
                'score': 0,
                'likes': 50,
                'comments': 10,
                'published_at': datetime.now().isoformat(),
                'topics': ['AI', 'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°'],
                'category': 'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°',
                'description': 'AIã‚’æ´»ç”¨ã—ãŸãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°æ‰‹æ³•ã«æ³¨ç›®ãŒé›†ã¾ã£ã¦ã„ã¾ã™',
                'quality_score': 70
            }
        ]
    
    def _remove_duplicate_trends(self, trends: List[Dict]) -> List[Dict]:
        """é‡è¤‡è¨˜äº‹ã‚’é™¤å»"""
        seen_urls = set()
        seen_titles = set()
        unique_trends = []
        
        for trend in trends:
            url = trend.get('url', '')
            title = trend.get('title', '')
            
            if url not in seen_urls and title not in seen_titles:
                seen_urls.add(url)
                seen_titles.add(title)
                unique_trends.append(trend)
        
        return unique_trends
    
    def _ensure_minimum_category_data(self, by_category: Dict[str, List[Dict]]) -> Dict[str, List[Dict]]:
        """å„ã‚«ãƒ†ã‚´ãƒªã«æœ€ä½é™ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿è¨¼"""
        fallback_data = {
            'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°': [
                {'title': 'Pythonæœ€æ–°é–‹ç™ºæ‰‹æ³•', 'source': 'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å°‚é–€', 'quality_score': 85, 'likes': 50, 'url': 'https://example.com/prog1'},
                {'title': 'JavaScript ES2024æ–°æ©Ÿèƒ½', 'source': 'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å°‚é–€', 'quality_score': 80, 'likes': 40, 'url': 'https://example.com/prog2'}
            ],
            'ã‚¦ã‚§ãƒ–é–‹ç™º': [
                {'title': 'Reactæœ€æ–°é–‹ç™ºæ‰‹æ³•', 'source': 'ã‚¦ã‚§ãƒ–é–‹ç™ºå°‚é–€', 'quality_score': 85, 'likes': 45, 'url': 'https://example.com/web1'},
                {'title': 'Vue.js 3å®Ÿè·µè¡“', 'source': 'ã‚¦ã‚§ãƒ–é–‹ç™ºå°‚é–€', 'quality_score': 80, 'likes': 35, 'url': 'https://example.com/web2'}
            ],
            'ç”ŸæˆAI': [
                {'title': 'ChatGPTæ´»ç”¨äº‹ä¾‹é›†', 'source': 'ç”ŸæˆAIå°‚é–€', 'quality_score': 90, 'likes': 60, 'url': 'https://example.com/ai1'},
                {'title': 'Claudeæœ€æ–°æ©Ÿèƒ½è§£èª¬', 'source': 'ç”ŸæˆAIå°‚é–€', 'quality_score': 85, 'likes': 50, 'url': 'https://example.com/ai2'}
            ],
            'ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ãƒ»AIé–‹ç™º': [
                {'title': 'æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«æœ€é©åŒ–', 'source': 'ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹å°‚é–€', 'quality_score': 88, 'likes': 55, 'url': 'https://example.com/ds1'},
                {'title': 'ãƒ‡ãƒ¼ã‚¿åˆ†ææ‰‹æ³•ã®æ¯”è¼ƒ', 'source': 'ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹å°‚é–€', 'quality_score': 82, 'likes': 42, 'url': 'https://example.com/ds2'}
            ],
            'ã‚­ãƒ£ãƒªã‚¢': [
                {'title': 'è»¢è·å¸‚å ´ã®æœ€æ–°å‹•å‘', 'source': 'ã‚­ãƒ£ãƒªã‚¢å°‚é–€', 'quality_score': 75, 'likes': 30, 'url': 'https://example.com/career1'},
                {'title': 'ã‚¹ã‚­ãƒ«ã‚¢ãƒƒãƒ—ã®ãƒã‚¤ãƒ³ãƒˆ', 'source': 'ã‚­ãƒ£ãƒªã‚¢å°‚é–€', 'quality_score': 70, 'likes': 25, 'url': 'https://example.com/career2'}
            ],
            'ãƒ“ã‚¸ãƒã‚¹': [
                {'title': 'DXæ¨é€²ã®æœ€æ–°äº‹ä¾‹', 'source': 'ãƒ“ã‚¸ãƒã‚¹å°‚é–€', 'quality_score': 80, 'likes': 40, 'url': 'https://example.com/biz1'},
                {'title': 'ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°æˆ¦ç•¥ã®é©æ–°', 'source': 'ãƒ“ã‚¸ãƒã‚¹å°‚é–€', 'quality_score': 75, 'likes': 35, 'url': 'https://example.com/biz2'}
            ],
            'å‹‰å¼·ãƒ»è‡ªå·±å•“ç™º': [
                {'title': 'åŠ¹ç‡çš„å­¦ç¿’æ³•ã®ç§‘å­¦', 'source': 'å­¦ç¿’ãƒ»è‡ªå·±å•“ç™ºå°‚é–€', 'quality_score': 75, 'likes': 30, 'url': 'https://example.com/study1'},
                {'title': 'ç¿’æ…£åŒ–æˆåŠŸã®ç§˜è¨£', 'source': 'å­¦ç¿’ãƒ»è‡ªå·±å•“ç™ºå°‚é–€', 'quality_score': 70, 'likes': 25, 'url': 'https://example.com/study2'}
            ]
        }
        
        for category, trends in by_category.items():
            if len(trends) < 2 and category in fallback_data:
                needed = 2 - len(trends)
                by_category[category].extend(fallback_data[category][:needed])
        
        return by_category
    
    def format_trends_for_discord(self, trends: List[Dict], max_display: int = 200) -> Dict:
        """Discordç”¨ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆ7ã‚«ãƒ†ã‚´ãƒªå¼·åˆ¶è¡¨ç¤ºï¼‰"""
        if not trends:
            return {
                "title": "ğŸ“Š é«˜å“è³ªãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±",
                "description": "ç¾åœ¨ãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ",
                "color": 0x9C27B0
            }
        
        # é‡è¤‡è¨˜äº‹ã‚’é™¤å»
        unique_trends = self._remove_duplicate_trends(trends)
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«æ•´ç†ï¼ˆã€Œä¸€èˆ¬ã€ã‚«ãƒ†ã‚´ãƒªã‚’é™¤å¤–ï¼‰
        by_category = {}
        required_categories = [
            'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°', 'ã‚¦ã‚§ãƒ–é–‹ç™º', 'ç”ŸæˆAI', 
            'ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ãƒ»AIé–‹ç™º', 'ã‚­ãƒ£ãƒªã‚¢', 'ãƒ“ã‚¸ãƒã‚¹', 'å‹‰å¼·ãƒ»è‡ªå·±å•“ç™º'
        ]
        
        # å„ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰æœ€ä½2ä»¶ã‚’ç¢ºä¿
        for category in required_categories:
            by_category[category] = []
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’å„ã‚«ãƒ†ã‚´ãƒªã«åˆ†é¡
        for trend in unique_trends[:max_display]:
            category = trend.get('category', 'ä¸€èˆ¬')
            if category in required_categories:
                by_category[category].append(trend)
        
        # å„ã‚«ãƒ†ã‚´ãƒªã«æœ€ä½2ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿è¨¼
        by_category = self._ensure_minimum_category_data(by_category)
        
        fields = []
        # æŒ‡å®šã—ãŸé †åºã§ã‚«ãƒ†ã‚´ãƒªã‚’è¡¨ç¤º
        for category in required_categories:
            cat_trends = by_category.get(category, [])
            if cat_trends:  # ã‚«ãƒ†ã‚´ãƒªã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿è¡¨ç¤º
                trend_list = []
                for trend in cat_trends[:2]:  # ã‚«ãƒ†ã‚´ãƒªã”ã¨ã«æœ€å¤§2ä»¶
                    title = trend['title']
                    if len(title) > 45:
                        title = title[:42] + "..."
                    
                    source = trend['source']
                    quality = trend.get('quality_score', 0)
                    
                    trend_info = f"ğŸ”¥ **{title}**\n"
                    trend_info += f"ğŸ“° {source} | å“è³ª: {quality}/100"
                    
                    if trend.get('likes', 0) > 0:
                        trend_info += f" | â¤ï¸ {trend['likes']}"
                    
                    trend_list.append(trend_info)
                
                if trend_list:
                    fields.append({
                        "name": f"ğŸ“‚ {category}",
                        "value": "\n\n".join(trend_list),
                        "inline": False
                    })
        
        # çµ±è¨ˆæƒ…å ±
        total_sources = len(set(t['source'] for t in unique_trends))
        avg_quality = sum(t.get('quality_score', 0) for t in unique_trends) / len(unique_trends) if unique_trends else 0
        
        fields.append({
            "name": "ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ",
            "value": f"â€¢ ç·ãƒ‡ãƒ¼ã‚¿æ•°: {len(unique_trends)}ä»¶\nâ€¢ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: {total_sources}ç¨®é¡\nâ€¢ å¹³å‡å“è³ªã‚¹ã‚³ã‚¢: {avg_quality:.1f}/100",
            "inline": False
        })
        
        return {
            "title": "ğŸš€ é«˜å“è³ªãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±ã‚·ã‚¹ãƒ†ãƒ ",
            "description": f"**7ã‚«ãƒ†ã‚´ãƒªå®Œå…¨ç¶²ç¾…**ã§å³é¸ã—ãŸ{len(unique_trends)}ä»¶ã®ãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±ã‚’ãŠå±Šã‘ï¼",
            "fields": fields,
            "color": 0x00D4AA,
            "footer": {
                "text": "ğŸ¯ é«˜å“è³ªãƒ‡ãƒ¼ã‚¿ | 7ã‚«ãƒ†ã‚´ãƒªå®Œå…¨è¡¨ç¤º | ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°"
            }
        }

# ä½¿ç”¨ä¾‹
async def demo_enhanced_trends_fixed():
    """ä¿®æ­£ç‰ˆãƒ‡ãƒ¢å®Ÿè¡Œ"""
    async with EnhancedTrendsManager() as manager:
        print("ğŸš€ ä¿®æ­£ç‰ˆEnhanced Trends Manager ãƒ†ã‚¹ãƒˆé–‹å§‹...")
        
        # å…¨ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰20ä»¶å–å¾—
        trends = await manager.get_enhanced_trends(max_trends=20)
        
        print(f"ğŸ“Š å–å¾—ãƒ‡ãƒ¼ã‚¿æ•°: {len(trends)}ä»¶")
        print("\n=== ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ ===")
        
        category_stats = {}
        for trend in trends:
            category = trend.get('category', 'æœªåˆ†é¡')
            if category not in category_stats:
                category_stats[category] = 0
            category_stats[category] += 1
        
        for category, count in category_stats.items():
            print(f"  {category}: {count}ä»¶")
        
        # Discordç”¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¾‹
        discord_data = manager.format_trends_for_discord(trends)
        print(f"\n=== Discord Embedæƒ…å ± ===")
        print(f"ğŸ“‹ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ•°: {len(discord_data.get('fields', []))}å€‹")
        
        for i, field in enumerate(discord_data.get('fields', []), 1):
            field_name = field.get('name', '')
            field_length = len(field.get('value', ''))
            print(f"  {i}. {field_name} ({field_length}æ–‡å­—)")

if __name__ == "__main__":
    asyncio.run(demo_enhanced_trends_fixed())