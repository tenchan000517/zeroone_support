#!/usr/bin/env python3
"""
åŒ…æ‹¬çš„ãƒ¡ãƒˆãƒªã‚¯ã‚¹å“è³ªè¨ºæ–­ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å…¨ãƒ‡ãƒ¼ã‚¿åé›†æ©Ÿèƒ½ã®å“è³ªå•é¡Œã‚’ç‰¹å®šãƒ»åˆ†æ
"""

import asyncio
import asyncpg
import os
import json
from datetime import datetime, date, timedelta
from dotenv import load_dotenv
from collections import defaultdict

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

class MetricsQualityAnalyzer:
    def __init__(self):
        self.db_url = os.getenv('NEON_DATABASE_URL')
        self.issues = []
        self.recommendations = []
    
    def add_issue(self, category, severity, description, technical_details=None):
        """å•é¡Œã‚’è¨˜éŒ²"""
        self.issues.append({
            'category': category,
            'severity': severity,  # CRITICAL, HIGH, MEDIUM, LOW
            'description': description,
            'technical_details': technical_details or ""
        })
    
    def add_recommendation(self, category, priority, solution, implementation=None):
        """ä¿®æ­£ææ¡ˆã‚’è¨˜éŒ²"""
        self.recommendations.append({
            'category': category,
            'priority': priority,  # URGENT, HIGH, MEDIUM, LOW
            'solution': solution,
            'implementation': implementation or ""
        })
    
    async def analyze_data_integrity(self, conn):
        """ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§åˆ†æ"""
        print("\nğŸ” ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§åˆ†æ")
        
        # 1. æ—¥ä»˜ã¨ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®æ•´åˆæ€§
        inconsistent_dates = await conn.fetch("""
            SELECT date, created_at, updated_at,
                   EXTRACT(DAY FROM (created_at - (date + INTERVAL '1 day'))) as day_diff
            FROM discord_metrics
            WHERE ABS(EXTRACT(DAY FROM (created_at - (date + INTERVAL '1 day')))) > 1
            ORDER BY date DESC
        """)
        
        if inconsistent_dates:
            print(f"âŒ æ—¥ä»˜æ•´åˆæ€§å•é¡Œ: {len(inconsistent_dates)}ä»¶")
            for row in inconsistent_dates:
                print(f"   ğŸ“… {row['date']}: ä½œæˆæ—¥æ™‚{row['created_at']} (å·®åˆ†: {row['day_diff']:.1f}æ—¥)")
            
            self.add_issue(
                "ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§", "HIGH",
                f"æ—¥ä»˜ã¨ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãŒæ•´åˆã—ãªã„ãƒ‡ãƒ¼ã‚¿ãŒ{len(inconsistent_dates)}ä»¶å­˜åœ¨",
                "å®Ÿè¡Œæ™‚åˆ»ã¨è¨˜éŒ²æ—¥ä»˜ã«ãšã‚ŒãŒã‚ã‚‹å¯èƒ½æ€§"
            )
        else:
            print("âœ… æ—¥ä»˜æ•´åˆæ€§: æ­£å¸¸")
        
        # 2. ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°ã®è«–ç†ãƒã‚§ãƒƒã‚¯
        invalid_messages = await conn.fetch("""
            SELECT date, daily_messages, daily_user_messages, daily_staff_messages,
                   (daily_user_messages + daily_staff_messages) as calculated_total
            FROM discord_metrics
            WHERE daily_messages != (daily_user_messages + daily_staff_messages)
            ORDER BY date DESC
        """)
        
        if invalid_messages:
            print(f"âŒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {len(invalid_messages)}ä»¶")
            for row in invalid_messages:
                print(f"   ğŸ“… {row['date']}: ç·è¨ˆ{row['daily_messages']} â‰  "
                      f"ãƒ¦ãƒ¼ã‚¶ãƒ¼{row['daily_user_messages']} + é‹å–¶{row['daily_staff_messages']} "
                      f"= {row['calculated_total']}")
            
            self.add_issue(
                "è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯", "CRITICAL",
                f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°ã®åˆè¨ˆè¨ˆç®—ãŒé–“é•ã£ã¦ã„ã‚‹({len(invalid_messages)}ä»¶)",
                "daily_messages = daily_user_messages + daily_staff_messages ã§ãªã„"
            )
        else:
            print("âœ… ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°è¨ˆç®—: æ­£å¸¸")
    
    async def analyze_data_quality(self, conn):
        """ãƒ‡ãƒ¼ã‚¿å“è³ªåˆ†æ"""
        print("\nğŸ“Š ãƒ‡ãƒ¼ã‚¿å“è³ªåˆ†æ")
        
        # 1. ã‚¼ãƒ­ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ—¥ã®åˆ†æ
        zero_message_days = await conn.fetch("""
            SELECT date, member_count, daily_messages
            FROM discord_metrics
            WHERE daily_messages = 0
            ORDER BY date DESC
            LIMIT 10
        """)
        
        total_days = await conn.fetchval("SELECT COUNT(*) FROM discord_metrics")
        zero_ratio = len(zero_message_days) / total_days * 100 if total_days > 0 else 0
        
        print(f"ğŸ“ˆ ã‚¼ãƒ­ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ—¥: {len(zero_message_days)}æ—¥ ({zero_ratio:.1f}%)")
        if zero_ratio > 50:
            self.add_issue(
                "ãƒ‡ãƒ¼ã‚¿å“è³ª", "HIGH",
                f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒ0ä»¶ã®æ—¥ãŒ{zero_ratio:.1f}%ã¨ç•°å¸¸ã«å¤šã„",
                "ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚«ã‚¦ãƒ³ãƒˆæ©Ÿèƒ½ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ãªã„å¯èƒ½æ€§"
            )
        
        # 2. ãƒãƒ£ãƒ³ãƒãƒ«çµ±è¨ˆã®å“è³ª
        channel_stats_quality = await conn.fetch("""
            SELECT date, 
                   jsonb_array_length(jsonb_object_keys(channel_message_stats)) as channel_count,
                   channel_message_stats
            FROM discord_metrics
            WHERE date >= CURRENT_DATE - INTERVAL '7 days'
            ORDER BY date DESC
        """)
        
        print("ğŸ“ ãƒãƒ£ãƒ³ãƒãƒ«çµ±è¨ˆå“è³ª:")
        channel_counts = []
        for row in channel_stats_quality:
            stats = json.loads(row['channel_message_stats'])
            channel_count = len(stats)
            channel_counts.append(channel_count)
            
            total_messages = sum(ch['user_messages'] for ch in stats.values())
            print(f"   ğŸ“… {row['date']}: {channel_count}ãƒãƒ£ãƒ³ãƒãƒ«, {total_messages}ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸")
            
            if channel_count == 0:
                self.add_issue(
                    "ãƒãƒ£ãƒ³ãƒãƒ«çµ±è¨ˆ", "MEDIUM",
                    f"{row['date']}: ãƒãƒ£ãƒ³ãƒãƒ«çµ±è¨ˆãŒç©º",
                    "ãƒãƒ£ãƒ³ãƒãƒ«åˆ¥ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚«ã‚¦ãƒ³ãƒˆãŒè¨˜éŒ²ã•ã‚Œã¦ã„ãªã„"
                )
        
        # ãƒãƒ£ãƒ³ãƒãƒ«æ•°ã®å¤‰å‹•ãŒç•°å¸¸ã§ãªã„ã‹ãƒã‚§ãƒƒã‚¯
        if len(channel_counts) > 1:
            avg_channels = sum(channel_counts) / len(channel_counts)
            if any(count < avg_channels * 0.5 for count in channel_counts):
                self.add_issue(
                    "ãƒãƒ£ãƒ³ãƒãƒ«çµ±è¨ˆ", "MEDIUM",
                    "ãƒãƒ£ãƒ³ãƒãƒ«æ•°ãŒæ—¥ã«ã‚ˆã£ã¦å¤§ããå¤‰å‹•ã—ã¦ã„ã‚‹",
                    "å…¨ãƒãƒ£ãƒ³ãƒãƒ«ã‚’æ­£ã—ãç›£è¦–ã§ãã¦ã„ãªã„å¯èƒ½æ€§"
                )
        
        # 3. ãƒ­ãƒ¼ãƒ«çµ±è¨ˆã®å“è³ª
        print("\nğŸ‘¥ ãƒ­ãƒ¼ãƒ«çµ±è¨ˆå“è³ª:")
        role_stats_quality = await conn.fetch("""
            SELECT date, role_counts
            FROM discord_metrics
            WHERE date >= CURRENT_DATE - INTERVAL '7 days'
            ORDER BY date DESC
        """)
        
        for row in role_stats_quality:
            role_data = json.loads(row['role_counts'])
            print(f"   ğŸ“… {row['date']}: {len(role_data)}ãƒ­ãƒ¼ãƒ«")
            
            # ãƒ­ãƒ¼ãƒ«çµ±è¨ˆã®è©³ç´°ãƒã‚§ãƒƒã‚¯
            total_members = 0
            empty_roles = 0
            for role_id, data in role_data.items():
                count = data['count']
                name = data['name']
                total_members += count
                if count == 0:
                    empty_roles += 1
                print(f"      - {name}: {count}äºº")
            
            if empty_roles > len(role_data) * 0.3:  # 30%ä»¥ä¸ŠãŒ0äºº
                self.add_issue(
                    "ãƒ­ãƒ¼ãƒ«çµ±è¨ˆ", "MEDIUM",
                    f"{row['date']}: ãƒ­ãƒ¼ãƒ«ã®{empty_roles}/{len(role_data)}ãŒ0äºº",
                    "ãƒ­ãƒ¼ãƒ«å–å¾—ã«å•é¡ŒãŒã‚ã‚‹å¯èƒ½æ€§"
                )
    
    async def analyze_collection_patterns(self, conn):
        """åé›†ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
        print("\nâ° åé›†ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ")
        
        # å®Ÿè¡Œæ™‚åˆ»ãƒ‘ã‚¿ãƒ¼ãƒ³
        execution_times = await conn.fetch("""
            SELECT date, 
                   EXTRACT(HOUR FROM created_at) as hour,
                   EXTRACT(MINUTE FROM created_at) as minute,
                   created_at
            FROM discord_metrics
            ORDER BY date DESC
            LIMIT 14
        """)
        
        print("ğŸ• å®Ÿè¡Œæ™‚åˆ»ãƒ‘ã‚¿ãƒ¼ãƒ³:")
        time_consistency = True
        expected_hour = 0  # æ—¥æœ¬æ™‚é–“0:00 = UTC 15:00
        
        for row in execution_times:
            hour = int(row['hour'])
            minute = int(row['minute'])
            print(f"   ğŸ“… {row['date']}: {hour:02d}:{minute:02d} UTC ({row['created_at']})")
            
            # å®Ÿè¡Œæ™‚åˆ»ãŒæœŸå¾…å€¤ã‹ã‚‰å¤§ãããšã‚Œã¦ã„ã‚‹å ´åˆ
            if abs(hour - 15) > 2:  # UTC 15:00 Â± 2æ™‚é–“
                time_consistency = False
        
        if not time_consistency:
            self.add_issue(
                "å®Ÿè¡Œã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«", "MEDIUM",
                "ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã®å®Ÿè¡Œæ™‚åˆ»ãŒä¸å®‰å®š",
                "æ—¥æœ¬æ™‚é–“0:00(UTC15:00)ã«å®Ÿè¡Œã•ã‚Œã‚‹ã¹ããŒç•°ãªã‚‹æ™‚åˆ»ã§å®Ÿè¡Œã•ã‚Œã¦ã„ã‚‹"
            )
            
            self.add_recommendation(
                "å®Ÿè¡Œã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«", "HIGH",
                "ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³è¨­å®šã‚’ç¢ºèªã—ã€cronã‚¸ãƒ§ãƒ–ã®æ™‚åˆ»ã‚’ä¿®æ­£",
                "metrics_collector.py:528ã®æ™‚åˆ»è¨­å®šã‚’ç¢ºèª"
            )
    
    async def analyze_message_counting_logic(self, conn):
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚«ã‚¦ãƒ³ãƒˆãƒ­ã‚¸ãƒƒã‚¯åˆ†æ"""
        print("\nğŸ’¬ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚«ã‚¦ãƒ³ãƒˆãƒ­ã‚¸ãƒƒã‚¯åˆ†æ")
        
        # æœ€è¿‘ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ã‚¿ãƒ¼ãƒ³
        recent_patterns = await conn.fetch("""
            SELECT date, daily_messages, daily_user_messages, daily_staff_messages,
                   member_count, engagement_score
            FROM discord_metrics
            WHERE date >= CURRENT_DATE - INTERVAL '14 days'
            ORDER BY date DESC
        """)
        
        print("ğŸ“Š æœ€è¿‘14æ—¥é–“ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ã‚¿ãƒ¼ãƒ³:")
        low_activity_days = 0
        
        for row in recent_patterns:
            total_msg = row['daily_messages']
            user_msg = row['daily_user_messages']
            staff_msg = row['daily_staff_messages']
            members = row['member_count']
            engagement = row['engagement_score']
            
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å¯†åº¦è¨ˆç®—
            msg_density = total_msg / members if members > 0 else 0
            
            print(f"   ğŸ“… {row['date']}: ç·{total_msg}ä»¶ (ğŸ‘¤{user_msg} + ğŸ‘®{staff_msg}), "
                  f"å¯†åº¦{msg_density:.3f}, ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸{engagement:.2f}")
            
            if total_msg == 0:
                low_activity_days += 1
        
        if low_activity_days > 7:  # åŠæ•°ä»¥ä¸ŠãŒ0ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            self.add_issue(
                "ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚«ã‚¦ãƒ³ãƒˆ", "CRITICAL",
                f"14æ—¥ä¸­{low_activity_days}æ—¥ã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒ0ä»¶",
                "on_message ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ãªã„å¯èƒ½æ€§"
            )
            
            self.add_recommendation(
                "ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚«ã‚¦ãƒ³ãƒˆ", "URGENT",
                "ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç›£è¦–æ©Ÿèƒ½ã®å®Œå…¨ãªè¦‹ç›´ã—ãŒå¿…è¦",
                """
1. on_message ã‚¤ãƒ™ãƒ³ãƒˆã®å‹•ä½œç¢ºèª
2. ãƒãƒ£ãƒ³ãƒãƒ«æ¨©é™ã®ç¢ºèª
3. ãƒ­ãƒ¼ãƒ«æ¨©é™ã®ç¢ºèª
4. ãƒ¡ãƒ¢ãƒªä¸Šã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã®ãƒªã‚»ãƒƒãƒˆã‚¿ã‚¤ãƒŸãƒ³ã‚°ä¿®æ­£
"""
            )
    
    async def generate_comprehensive_report(self):
        """åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        print("\n" + "="*80)
        print("ğŸ“‹ åŒ…æ‹¬çš„å•é¡Œåˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
        print("="*80)
        
        try:
            conn = await asyncpg.connect(self.db_url)
            
            await self.analyze_data_integrity(conn)
            await self.analyze_data_quality(conn)
            await self.analyze_collection_patterns(conn)
            await self.analyze_message_counting_logic(conn)
            
            await conn.close()
            
        except Exception as e:
            print(f"âŒ åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return
        
        # å•é¡Œã‚µãƒãƒªãƒ¼
        print("\n" + "="*50)
        print("ğŸš¨ ç™ºè¦‹ã•ã‚ŒãŸå•é¡Œ")
        print("="*50)
        
        if not self.issues:
            print("âœ… é‡å¤§ãªå•é¡Œã¯ç™ºè¦‹ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        else:
            severity_order = ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW']
            for severity in severity_order:
                severity_issues = [i for i in self.issues if i['severity'] == severity]
                if severity_issues:
                    severity_emoji = {'CRITICAL': 'ğŸ”´', 'HIGH': 'ğŸŸ ', 'MEDIUM': 'ğŸŸ¡', 'LOW': 'ğŸ”µ'}
                    print(f"\n{severity_emoji[severity]} {severity}ãƒ¬ãƒ™ãƒ« ({len(severity_issues)}ä»¶)")
                    for i, issue in enumerate(severity_issues, 1):
                        print(f"   {i}. [{issue['category']}] {issue['description']}")
                        if issue['technical_details']:
                            print(f"      ğŸ’¡ {issue['technical_details']}")
        
        # ä¿®æ­£ææ¡ˆ
        print("\n" + "="*50)
        print("ğŸ”§ ä¿®æ­£ææ¡ˆ")
        print("="*50)
        
        if not self.recommendations:
            print("ğŸ“ ç‰¹ã«ä¿®æ­£ææ¡ˆã¯ã‚ã‚Šã¾ã›ã‚“")
        else:
            priority_order = ['URGENT', 'HIGH', 'MEDIUM', 'LOW']
            for priority in priority_order:
                priority_recs = [r for r in self.recommendations if r['priority'] == priority]
                if priority_recs:
                    priority_emoji = {'URGENT': 'ğŸš¨', 'HIGH': 'âš¡', 'MEDIUM': 'ğŸ“', 'LOW': 'ğŸ’¡'}
                    print(f"\n{priority_emoji[priority]} {priority}å„ªå…ˆåº¦ ({len(priority_recs)}ä»¶)")
                    for i, rec in enumerate(priority_recs, 1):
                        print(f"   {i}. [{rec['category']}] {rec['solution']}")
                        if rec['implementation']:
                            print(f"      ğŸ› ï¸ å®Ÿè£…æ–¹æ³•:")
                            for line in rec['implementation'].strip().split('\n'):
                                if line.strip():
                                    print(f"         {line.strip()}")

async def main():
    analyzer = MetricsQualityAnalyzer()
    await analyzer.generate_comprehensive_report()

if __name__ == "__main__":
    asyncio.run(main())